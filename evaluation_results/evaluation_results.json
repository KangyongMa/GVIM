{
  "individual_results": [
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.3
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 1.2
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 7.0
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 1.0
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.8500000000000001
          },
          "final_score": 2.3000000000000003
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.04999999999999999
          },
          "final_score": 0.7
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.024962992828337954,
            "rouge_scores": 0.08794474935054243,
            "keyword_relevance": 0,
            "readability": 0.4329,
            "coherence": 0.1532421173597644
          },
          "final_score": 1.3980997190772895
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.020871196323280095,
            "rouge_scores": 0.1777777754193416,
            "keyword_relevance": 0,
            "readability": 0.16829999999999998,
            "coherence": 0.08823529411764706
          },
          "final_score": 0.9103685317205374
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.005386428550901994,
            "rouge_scores": 0.06926406830606624,
            "keyword_relevance": 0,
            "readability": 0.7009000000000001,
            "coherence": 0.0
          },
          "final_score": 1.5511009937139366
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.02250587529131595,
            "rouge_scores": 0.13721232967469985,
            "keyword_relevance": 0,
            "readability": 0.48810000000000003,
            "coherence": 0.02631578947368421
          },
          "final_score": 1.3482679888794
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.21797469124036953,
            "rouge_scores": 0.38509316392160226,
            "keyword_relevance": 0,
            "readability": 0.3832,
            "coherence": 1.0
          },
          "final_score": 3.972535710323944
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.018350800501360648,
            "rouge_scores": 0.1745571636907902,
            "keyword_relevance": 0,
            "readability": 0.2414,
            "coherence": 0.125
          },
          "final_score": 1.1186159283843016
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.12673718536830808,
            "rouge_scores": 0.2272727236019284,
            "keyword_relevance": 0,
            "readability": 0.5321,
            "coherence": 1.0
          },
          "final_score": 3.7722198179404733
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.004719379523099929,
            "rouge_scores": 0.08852258684712216,
            "keyword_relevance": 0.3,
            "readability": 0.3787,
            "coherence": 0.30256783421257105
          },
          "final_score": 2.149019601165586
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.002305316198112142,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.5053,
            "coherence": 0.13675213675213674
          },
          "final_score": 2.288714905900498
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.43226499779045735,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.864529995580915
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 1.7646153653770578e-14,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.36619999999999997,
            "coherence": 1.0
          },
          "final_score": 2.7324000000000352
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.05965613675142931,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.33880000000000005,
            "coherence": 0.15384615384615385
          },
          "final_score": 1.1046045811951664
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.0016310729616735356,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.13949999999999999,
            "coherence": 0.0
          },
          "final_score": 0.28226214592334703
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.0008989766761364341,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.001797953352273
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.6240547246827638,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.248109449365528
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.002146612738087998,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.0
          },
          "final_score": 0.004293225476175996
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.0
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 2.8000000000000003
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 3.9000000000000004
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7444163171912002,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 5.1664979031472
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.7625
          },
          "final_score": 4.525
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 3.55
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.8
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6486102712100578,
            "keyword_relevance": 0,
            "conciseness": 0.39285714285714285
          },
          "final_score": 4.677375912974632
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.8
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0.5,
            "conciseness": 0.4
          },
          "final_score": 4.800000000000001
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.8
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.844358184985233,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 5.866149109911398
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.8
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.2945473024773706,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.067283814864224
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.2945473024773706,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.067283814864224
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.2945473024773706,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.067283814864224
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 3.3999999999999995
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5857142857142856
          },
          "final_score": 2.9714285714285715
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8285714285714286
          },
          "final_score": 3.4571428571428573
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4642857142857143
          },
          "final_score": 3.9285714285714284
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7714285714285714
          },
          "final_score": 3.342857142857143
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 2.5
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.43921302050623523,
            "keyword_relevance": 0,
            "conciseness": 0.6857142857142857
          },
          "final_score": 4.006706694465983
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 1.4000000000000001
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 1.7999999999999998
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.2713169695446387,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 2.427901817267832
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7357142857142858
          },
          "final_score": 3.271428571428572
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.7
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 6.1
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6156820946645277,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.394092567987166
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 4.9
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.6156820946645277,
            "keyword_relevance": 0.6,
            "conciseness": 0.35
          },
          "final_score": 5.594092567987166
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.8310849912698232,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 5.986509947618939
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.65
          },
          "final_score": 3.1
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.8190883190883191,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.2763532763532766
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.765886287625418,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.063545150501673
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.8679775280898876,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.471910112359551
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.952247191011236,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.808988764044944
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.7747035573122529,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.098814229249012
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.7668539325842696,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.067415730337078
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.7275280898876404,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.910112359550562
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.37953995157384984,
            "coherence": 0.07142857142857142,
            "keyword_relevance": 0
          },
          "final_score": 1.7324455205811138
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5576923076923077
          },
          "final_score": 2.9153846153846152
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.46923076923076923
          },
          "final_score": 3.9384615384615387
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.7346153846153846
          },
          "final_score": 5.669230769230769
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.2319489374528313,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.5916936247169877
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.2319489374528313,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.5916936247169877
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.2319489374528313,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.5916936247169877
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7461538461538462
          },
          "final_score": 3.292307692307692
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4807692307692308
          },
          "final_score": 2.7615384615384615
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8493526356653118,
            "keyword_relevance": 0,
            "conciseness": 0.8071428571428572
          },
          "final_score": 6.710401528277585
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7941146308676144,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 5.064687785205686
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.602356785416275,
            "keyword_relevance": 0,
            "conciseness": 0.8071428571428572
          },
          "final_score": 5.228426426783365
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.45690692619185835,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.5414415571511504
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6056916579690956,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 5.534149947814574
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.6024162748522703,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 4.014497649113622
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.7357142857142858
          },
          "final_score": 4.4714285714285715
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8785714285714286
          },
          "final_score": 3.557142857142857
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 3.5888888888888886
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 4.788888888888889
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 1.7999999999999998
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494850021680094,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 5.696910013008056
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.0
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 1.5000000000000002
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.7833333333333334
          },
          "final_score": 4.566666666666666
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.7
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.12925932065340295,
            "rouge_scores": 0.27927305855783713,
            "keyword_relevance": 0.3,
            "readability": 0.6522,
            "coherence": 0.10741687979539642
          },
          "final_score": 2.9362985180132735
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.005338430775184953,
            "rouge_scores": 0.22375478430468151,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.03571428571428571
          },
          "final_score": 0.5296150015883043
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.006947883771669369,
            "rouge_scores": 0.08202305841842902,
            "keyword_relevance": 0.3,
            "readability": 0.22210000000000002,
            "coherence": 0.24
          },
          "final_score": 1.7021418843801968
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.006482491239183015,
            "rouge_scores": 0.07594936514447477,
            "keyword_relevance": 0.6,
            "readability": 0.49450000000000005,
            "coherence": 0.09351351351351352
          },
          "final_score": 2.5408907397943423
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.017335685887215155,
            "rouge_scores": 0.16515151073044096,
            "keyword_relevance": 0,
            "readability": 0.7114,
            "coherence": 1.0
          },
          "final_score": 3.7877743932353125
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.0041548034090245975,
            "rouge_scores": 0.10852712996574727,
            "keyword_relevance": 0.3,
            "readability": 0.2864,
            "coherence": 0.09417562724014336
          },
          "final_score": 1.5865151212298305
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.06863269655992758,
            "rouge_scores": 0.18898550232273234,
            "keyword_relevance": 0,
            "readability": 0.6877,
            "coherence": 1.0
          },
          "final_score": 3.89063639776532
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.013723860568203244,
            "rouge_scores": 0.06668560949874273,
            "keyword_relevance": 0.5,
            "readability": 0.5848,
            "coherence": 0.1497863247863248
          },
          "final_score": 2.629991589706542
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.7
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4307692307692308
          },
          "final_score": 3.861538461538462
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8346153846153845
          },
          "final_score": 3.469230769230769
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.6576923076923077
          },
          "final_score": 5.515384615384615
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4307692307692308
          },
          "final_score": 2.661538461538462
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7428571428571429
          },
          "final_score": 3.2857142857142856
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.816548337549573,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 6.799290025297438
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8476849869690308,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 6.0861099218141845
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8449847969312754,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 5.369908781587652
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.848381950018701,
            "keyword_relevance": 0,
            "conciseness": 0.3857142857142857
          },
          "final_score": 5.8617202715407775
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.8449847969312754,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 5.369908781587652
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.8491012296535128,
            "keyword_relevance": 0,
            "conciseness": 0.8428571428571429
          },
          "final_score": 6.7803216636353625
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494817740944518,
            "keyword_relevance": 0,
            "conciseness": 0.8571428571428572
          },
          "final_score": 6.811176358852426
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 3.2
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.9999999999999998
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0.3,
            "conciseness": 0.4
          },
          "final_score": 3.2
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7035254074021251,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.921152444412751
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 3.55
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7224125997548738,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 5.634475598529242
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7224125997548738,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 5.634475598529242
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7680496342063647,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.608297805238188
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494850021680094,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 5.7969100130080555
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7677415805742197,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.481449483445319
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.358727383018544,
            "keyword_relevance": 0.3,
            "conciseness": 0.5
          },
          "final_score": 3.7523642981112637
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.7224125997548738,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 5.634475598529242
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.22614818701306552,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.23076923076923078
          },
          "final_score": 0.9138348355645926
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.09987870720866435,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.5909090909090908
          },
          "final_score": 1.3815755962355103
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.3076594054823494,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.13333333333333333
          },
          "final_score": 0.8819854776313654
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.05663917897450404,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.1132783579490084
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.3089435388575278,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.23529411764705882
          },
          "final_score": 1.088475313009173
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.5542351938743796,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.10847038774876
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.31716861165328925,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.634337223306579
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.2862296378044108,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.16
          },
          "final_score": 0.8924592756088217
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.09495146210251698,
            "rouge_scores": 0.23118279237969622,
            "keyword_relevance": 0,
            "readability": 0.6234000000000001,
            "coherence": 0.06971153846153846
          },
          "final_score": 2.0384915858875035
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.06510867081169568,
            "rouge_scores": 0.20977279585476025,
            "keyword_relevance": 0,
            "readability": 0.5189,
            "coherence": 0.4927536231884058
          },
          "final_score": 2.573070179709723
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.00944194219264184,
            "rouge_scores": 0.06917549502898114,
            "keyword_relevance": 0,
            "readability": 0.5493,
            "coherence": 0.09990540860106079
          },
          "final_score": 1.4556456916453675
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.17588181044237433,
            "rouge_scores": 0.3536231844323529,
            "keyword_relevance": 0,
            "readability": 0.7384999999999999,
            "coherence": 0.1111111111111111
          },
          "final_score": 2.7582322119716767
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.33180774028439425,
            "rouge_scores": 0.59207458710809,
            "keyword_relevance": 0,
            "readability": 0.664,
            "coherence": 1.0
          },
          "final_score": 5.1757646547849685
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.01440896159382017,
            "rouge_scores": 0.20833333003906254,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.0967741935483871
          },
          "final_score": 0.6390329703625397
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.1431712315455507,
            "rouge_scores": 0.23740510278684382,
            "keyword_relevance": 0,
            "readability": 0.637,
            "coherence": 1.0
          },
          "final_score": 4.035152668664789
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.01626285047179945,
            "rouge_scores": 0.12478632263307037,
            "keyword_relevance": 0,
            "readability": 0.3452,
            "coherence": 0.0982142857142857
          },
          "final_score": 1.1689269176383112
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 3.8
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 0.8999999999999999
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 0.8999999999999999
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.4476034783309035,
            "keyword_relevance": 0,
            "conciseness": 0.5916666666666666
          },
          "final_score": 3.8689542033187543
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7583333333333333
          },
          "final_score": 3.3166666666666664
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.7526881720430108,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.010752688172043
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.9046153846153846,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.618461538461538
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.8560606060606061,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.424242424242425
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.9166666666666667,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.666666666666668
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.3755892255892256,
            "coherence": 0.13636363636363635,
            "keyword_relevance": 0
          },
          "final_score": 1.9114478114478115
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.764367816091954,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.057471264367816
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.8153153153153153,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.261261261261262
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.8357664233576643,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.343065693430657
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5916666666666666
          },
          "final_score": 2.9833333333333334
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6833333333333333
          },
          "final_score": 3.1666666666666665
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.6333333333333333
          },
          "final_score": 4.266666666666667
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.4190507063721588,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.914304238232953
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.9083333333333333
          },
          "final_score": 3.616666666666667
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6916666666666667
          },
          "final_score": 3.1833333333333336
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6
          },
          "final_score": 3.0
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.006727229448604617,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.013454458897209
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.007939087147543497,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.0
          },
          "final_score": 0.015878174295086995
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.010275474580767148,
            "rouge_scores": 0.08333333063802092,
            "keyword_relevance": 0,
            "readability": 0.5236,
            "coherence": 1.0
          },
          "final_score": 3.234417610437576
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.012673718536830811,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.30870000000000003,
            "coherence": 1.0
          },
          "final_score": 2.642747437073662
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.022613617379612153,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.5693,
            "coherence": 1.0
          },
          "final_score": 3.1838272347592245
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.006305393737187353,
            "rouge_scores": 0.08994049860857167,
            "keyword_relevance": 0,
            "readability": 0.5524,
            "coherence": 0.21996996996996998
          },
          "final_score": 1.7372317246314584
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.0
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.014628063653657535,
            "rouge_scores": 0.08333333020833346,
            "keyword_relevance": 0,
            "readability": 0.3933,
            "coherence": 1.0
          },
          "final_score": 2.9825227877239824
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.009338907667359573,
            "rouge_scores": 0.23846153393088163,
            "keyword_relevance": 0.3,
            "readability": 0.4542,
            "coherence": 0.06340579710144928
          },
          "final_score": 2.130812477399381
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.029362290010288384,
            "rouge_scores": 0.5630630583888881,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.1848506967983536
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.0756083295989952,
            "rouge_scores": 0.2810530169252122,
            "keyword_relevance": 0,
            "readability": 0.8078,
            "coherence": 1.0
          },
          "final_score": 4.328922693048415
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.0065958005888164355,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.13636363636363635
          },
          "final_score": 0.2859188739049056
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.5452353574508253,
            "rouge_scores": 0.7071604888343997,
            "keyword_relevance": 0,
            "readability": 0.593,
            "coherence": 1.0
          },
          "final_score": 5.690791692570451
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.0013111446659798528,
            "rouge_scores": 0.07017543601108042,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.1429731613541207
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.010859480700217564,
            "rouge_scores": 0.07843137061130338,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.178581702623042
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.002839490068636794,
            "rouge_scores": 0.19257702696858572,
            "keyword_relevance": 0,
            "readability": 0.1801,
            "coherence": 0.12132352941176472
          },
          "final_score": 0.9936800928979744
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6076923076923078
          },
          "final_score": 3.0153846153846153
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.9615384615384616
          },
          "final_score": 3.723076923076923
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.46923076923076923
          },
          "final_score": 3.9384615384615387
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3739917250325967,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.5439503501955802
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.9615384615384616
          },
          "final_score": 3.723076923076923
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3766892409759498,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.560135445855699
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.005129082097094954,
            "rouge_scores": 0.09660063229262911,
            "keyword_relevance": 0,
            "readability": 0.5321,
            "coherence": 0.23142857142857143
          },
          "final_score": 1.7305165716365911
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.036260056295236785,
            "rouge_scores": 0.12121211790633617,
            "keyword_relevance": 0,
            "readability": 0.3696,
            "coherence": 1.0
          },
          "final_score": 3.0541443484031463
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.03320585776558893,
            "rouge_scores": 0.20873015467990372,
            "keyword_relevance": 0,
            "readability": 0.5317000000000001,
            "coherence": 0.07692307692307693
          },
          "final_score": 1.7011181787371394
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.005015716481729795,
            "rouge_scores": 0.10526315501385049,
            "keyword_relevance": 0.5,
            "readability": 0.6082,
            "coherence": 0.10810810810810811
          },
          "final_score": 2.6531739592073764
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.05289475450266781,
            "rouge_scores": 0.19298245188827343,
            "keyword_relevance": 0,
            "readability": 0.5388000000000001,
            "coherence": 0.1111111111111111
          },
          "final_score": 1.791576635004105
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.01062966632179831,
            "rouge_scores": 0.19381787313798293,
            "keyword_relevance": 0,
            "readability": 0.4644,
            "coherence": 1.0
          },
          "final_score": 3.3376950789195625
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.005235475585773997,
            "rouge_scores": 0.16031745540215436,
            "keyword_relevance": 0,
            "readability": 0.19030000000000002,
            "coherence": 1.0
          },
          "final_score": 2.711705861975857
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.003593400513595791,
            "rouge_scores": 0.06349206022675755,
            "keyword_relevance": 0,
            "readability": 0.0718,
            "coherence": 0.14285714285714285
          },
          "final_score": 0.5634852071949924
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 3.8
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.6875
          },
          "final_score": 5.575
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8136243778757545,
            "keyword_relevance": 0,
            "conciseness": 0.4375
          },
          "final_score": 5.756746267254527
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5118474949411222,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 3.971084969646734
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5326830438674708,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.196098263204825
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 4.875
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.9556677890011223,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.822671156004489
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.8742038216560509,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.496815286624205
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.9361873990306946,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.744749596122778
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.5412069144031109,
            "coherence": 0.1798579182630907,
            "keyword_relevance": 0
          },
          "final_score": 2.7044014124017157
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.7115384615384616,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.846153846153847
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.9447674418604651,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.779069767441861
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.5316455696202531,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.1265822784810124
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.5386847195357833,
            "coherence": 0.5454545454545454,
            "keyword_relevance": 0
          },
          "final_score": 3.7911025145067696
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.55
          },
          "final_score": 1.7000000000000002
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 0.8999999999999999
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 7.0
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.04999999999999999
          },
          "final_score": 0.7
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.75
          },
          "final_score": 2.1
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8418230036734907,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.925938022040944
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6659200361890711,
            "keyword_relevance": 0,
            "conciseness": 0.825
          },
          "final_score": 5.645520217134426
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.6572036530002596,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.9432219180015577
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5447742336539133,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 3.8686454019234793
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6941174914621671,
            "keyword_relevance": 0,
            "conciseness": 0.7125
          },
          "final_score": 5.589704948773003
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.6375082816495317,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.82504968989719
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.6521785945655003,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 5.788071567393001
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.36568920009648553,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 2.9941352005789135
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.664751369872657,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.9885082192359422
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.15122318940160828,
            "keyword_relevance": 0,
            "conciseness": 0.25
          },
          "final_score": 1.4073391364096497
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6937535934623089,
            "keyword_relevance": 0,
            "conciseness": 0.25
          },
          "final_score": 4.662521560773854
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0.6,
            "conciseness": 0.25
          },
          "final_score": 2.3
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.6368697998340214,
            "keyword_relevance": 0,
            "conciseness": 0.6
          },
          "final_score": 5.021218799004128
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.7
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.03360057063582355,
            "rouge_scores": 0.13923013558361094,
            "keyword_relevance": 0.5,
            "readability": 0.5625,
            "coherence": 0.1358333333333333
          },
          "final_score": 2.742328079105536
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.04252941997764145,
            "rouge_scores": 0.18115054651111492,
            "keyword_relevance": 0.3,
            "readability": 0.4698,
            "coherence": 0.11103896103896103
          },
          "final_score": 2.209037855055435
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.0025579476037043062,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.23076923076923078
          },
          "final_score": 0.4666543567458702
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.008319506012561522,
            "rouge_scores": 0.09259258976337457,
            "keyword_relevance": 0,
            "readability": 0.285,
            "coherence": 1.0
          },
          "final_score": 2.771824191551872
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.1022875701616399,
            "rouge_scores": 0.18176328003309236,
            "keyword_relevance": 0.3,
            "readability": 0.4915,
            "coherence": 1.0
          },
          "final_score": 4.151101700389464
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.02786796785618582,
            "rouge_scores": 0.2231219027130303,
            "keyword_relevance": 0,
            "readability": 0.1497,
            "coherence": 1.0
          },
          "final_score": 2.8013797411384322
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.03566087490853475,
            "rouge_scores": 0.12142214878338914,
            "keyword_relevance": 0,
            "readability": 0.642,
            "coherence": 0.3
          },
          "final_score": 2.198166047383848
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.0017904773791302365,
            "rouge_scores": 0.05176366616780603,
            "keyword_relevance": 0.3,
            "readability": 0.6972,
            "coherence": 0.23060958076437948
          },
          "final_score": 2.5627274486226312
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 4.580952380952381
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.7785714285714286
          },
          "final_score": 5.757142857142857
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.16666666666666669
          },
          "final_score": 2.1333333333333333
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8057207767530914,
            "keyword_relevance": 0.3,
            "conciseness": 0.04999999999999999
          },
          "final_score": 5.534324660518548
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7114589903838312,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 4.868753942302987
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.48419177859334017,
            "keyword_relevance": 0,
            "conciseness": 0.3357142857142857
          },
          "final_score": 3.576579242988612
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 4.485714285714286
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 4.7749999999999995
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5455695769128774,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 4.5734174614772645
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 5.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0.5,
            "conciseness": 0.5
          },
          "final_score": 2.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.7625
          },
          "final_score": 4.525
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0.5,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.00017569118259751015,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.6877,
            "coherence": 1.0
          },
          "final_score": 3.3757513823651952
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.43685388602012803,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.42105263157894735
          },
          "final_score": 1.7158130351981509
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.7572149768748418,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.3
          },
          "final_score": 2.114429953749684
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.0052810813622024685,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.7192000000000001,
            "coherence": 0.14802156907420064
          },
          "final_score": 2.7450053008728066
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.45243199496117836,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.904863989922357
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.015137577953359387,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.1818,
            "coherence": 0.13043478260869565
          },
          "final_score": 1.6547447211241102
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.910891118267805,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.3333333333333333
          },
          "final_score": 2.4884489032022765
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.43729999999999997,
            "coherence": 0.125
          },
          "final_score": 2.1246
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7606054372569568,
            "keyword_relevance": 0,
            "conciseness": 0.2272727272727273
          },
          "final_score": 5.018178078087195
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.20454545454545453
          },
          "final_score": 3.4090909090909087
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8545454545454545
          },
          "final_score": 3.509090909090909
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.33482921455077186,
            "keyword_relevance": 0,
            "conciseness": 0.3181818181818182
          },
          "final_score": 2.6453389236682674
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.4318181818181818
          },
          "final_score": 1.4636363636363636
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.847364763164137,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 5.084188578984822
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.15909090909090912
          },
          "final_score": 4.518181818181818
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8473142044819356,
            "keyword_relevance": 0,
            "conciseness": 0.13636363636363635
          },
          "final_score": 5.356612499618886
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 4.788888888888889
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.835079232849358,
            "keyword_relevance": 0,
            "conciseness": 0.788888888888889
          },
          "final_score": 6.588253174873926
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7008932253783355,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 5.0053593522700135
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6004837598270378,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.302902558962227
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7083141852440893,
            "keyword_relevance": 0,
            "conciseness": 0.6333333333333333
          },
          "final_score": 5.516551778131202
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 5.977777777777778
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 4.777777777777778
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.239175173134627,
            "keyword_relevance": 0,
            "conciseness": 0.9444444444444444
          },
          "final_score": 3.323939927696651
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5387729528611732,
            "keyword_relevance": 0,
            "conciseness": 0.5777777777777777
          },
          "final_score": 4.388193272722595
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.4222222222222222
          },
          "final_score": 1.4444444444444442
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.6277777777777778
          },
          "final_score": 1.8555555555555556
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.21674282643014187,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 3.08934584746974
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5777777777777777
          },
          "final_score": 1.7555555555555555
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 2.3777777777777778
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5538316915516275,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 5.100767927087543
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.7526881720430108,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.010752688172043
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.8297872340425532,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.319148936170214
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.9477611940298507,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.791044776119404
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.4036226930963773,
            "coherence": 0.15789473684210525,
            "keyword_relevance": 0
          },
          "final_score": 2.0881749829118252
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.4536144578313253,
            "coherence": 0.1,
            "keyword_relevance": 0
          },
          "final_score": 2.1144578313253013
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.8888888888888888,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.555555555555555
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.8208955223880596,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.2835820895522385
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.4597972972972973,
            "coherence": 0.125,
            "keyword_relevance": 0
          },
          "final_score": 2.2141891891891894
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.2774211241007959,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.0645267446047755
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6811616339052197,
            "keyword_relevance": 0,
            "conciseness": 0.8166666666666667
          },
          "final_score": 5.720303136764651
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.775
          },
          "final_score": 3.35
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.2774211241007959,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.0645267446047755
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.2774211241007959,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.0645267446047755
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.21666666666666667
          },
          "final_score": 2.2333333333333334
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8666666666666667
          },
          "final_score": 4.733333333333333
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5083333333333333
          },
          "final_score": 2.816666666666667
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5222663574360856,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.1335981446165135
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.4198697832203965,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 3.519218699322378
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7849588057137018,
            "keyword_relevance": 0.5,
            "conciseness": 0.45
          },
          "final_score": 6.60975283428221
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.25849828152719156,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 2.2509896891631493
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 3.5777777777777775
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.7647546620896754,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.255194639204719
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7055841372028964,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 5.233504823217379
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.8335961651664248,
            "keyword_relevance": 0,
            "conciseness": 0.788888888888889
          },
          "final_score": 6.5793547687763265
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.17408419597052094,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 2.833394064712014
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3279456797951684,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 3.2676740787710106
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.4604517765290359,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.5627106591742153
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.32824523119930515,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 2.6694713871958307
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7346258018525504,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 6.18553258889308
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.7877925478981702,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.393421954055688
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4307692307692308
          },
          "final_score": 2.661538461538462
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.3807692307692308
          },
          "final_score": 2.5615384615384618
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7846153846153846
          },
          "final_score": 3.3692307692307693
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8404941516496228,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 5.7429649098977364
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5192307692307692
          },
          "final_score": 2.8384615384615386
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5793555151023739,
            "keyword_relevance": 0,
            "conciseness": 0.6461538461538461
          },
          "final_score": 4.768440782921935
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4423076923076923
          },
          "final_score": 3.8846153846153846
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0.5,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.9517543859649122,
            "coherence": 1.0,
            "keyword_relevance": 0.5
          },
          "final_score": 8.307017543859649
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.6906779661016949,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.76271186440678
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.7153846153846154,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.861538461538461
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.553217011995638,
            "coherence": 0.22857142857142856,
            "keyword_relevance": 0
          },
          "final_score": 2.8985823336968375
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.6929824561403508,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.771929824561404
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.5030655391120507,
            "coherence": 0.13636363636363635,
            "keyword_relevance": 0.5
          },
          "final_score": 3.921353065539112
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.9824561403508771,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.9298245614035086
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.4964774668826414,
            "coherence": 0.4037433155080214,
            "keyword_relevance": 0
          },
          "final_score": 3.19713981405463
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6768024918869524,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 5.9358149513217136
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.775
          },
          "final_score": 3.35
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0.3,
            "conciseness": 0.3
          },
          "final_score": 4.2
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5028047226801402,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 3.7168283360808414
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.65
          },
          "final_score": 4.3
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.725
          },
          "final_score": 3.2499999999999996
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.00471344741211272,
            "rouge_scores": 0.11881342364419607,
            "keyword_relevance": 0.5,
            "readability": 0.4512,
            "coherence": 0.1125
          },
          "final_score": 2.3744537421126175
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.05832443195452451,
            "rouge_scores": 0.5806637758721064,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.277976415653262
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.002216562275983051,
            "rouge_scores": 0.09803921245674752,
            "keyword_relevance": 0,
            "readability": 0.1107,
            "coherence": 0.3103448275862069
          },
          "final_score": 1.042601204637875
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.274062371732805,
            "rouge_scores": 0.3910256360569389,
            "keyword_relevance": 0,
            "readability": 0.7723,
            "coherence": 1.0
          },
          "final_score": 4.874776015579488
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.09279771067975602,
            "rouge_scores": 0.277504100102779,
            "keyword_relevance": 0,
            "readability": 0.21559999999999999,
            "coherence": 0.0625
          },
          "final_score": 1.2968036215650702
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.022899506146904156,
            "rouge_scores": 0.10337671779807019,
            "keyword_relevance": 0,
            "readability": 0.4661,
            "coherence": 0.1111111111111111
          },
          "final_score": 1.406974670112171
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.1584450133726893,
            "rouge_scores": 0.23329075703264404,
            "keyword_relevance": 0,
            "readability": 0.6470999999999999,
            "coherence": 1.0
          },
          "final_score": 4.077671540810667
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.026111767084014317,
            "rouge_scores": 0.09126508172138952,
            "keyword_relevance": 1.0,
            "readability": 0.5869,
            "coherence": 0.13779239766081872
          },
          "final_score": 3.684138492932445
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 4.580952380952381
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8361409035585018,
            "keyword_relevance": 0,
            "conciseness": 0.4095238095238095
          },
          "final_score": 5.83589304039863
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 1.2
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.2142857142857143
          },
          "final_score": 3.428571428571429
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7820413910350874,
            "keyword_relevance": 0,
            "conciseness": 0.9261904761904762
          },
          "final_score": 6.5446292985914765
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 4.8
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.25
          },
          "final_score": 4.699999999999999
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8364248848539555,
            "keyword_relevance": 0,
            "conciseness": 0.25
          },
          "final_score": 5.518549309123734
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.6099354893337741,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.6596129360026444
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6099354893337741,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.6596129360026444
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.41818181818181815
          },
          "final_score": 3.836363636363636
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.15909090909090912
          },
          "final_score": 4.518181818181818
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.15909090909090912
          },
          "final_score": 2.118181818181818
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.9361702127659575,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.74468085106383
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.8166666666666667,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.2666666666666675
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.9444444444444444,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.777777777777779
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.6705407969639469,
            "coherence": 0.532258064516129,
            "keyword_relevance": 0
          },
          "final_score": 4.278937381404175
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.8611111111111112,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.444444444444445
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.8416666666666667,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.366666666666667
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.9472222222222222,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.788888888888889
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.4126262626262626,
            "coherence": 0.13636363636363635,
            "keyword_relevance": 0
          },
          "final_score": 2.0595959595959594
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494849564456985,
            "keyword_relevance": 0,
            "conciseness": 0.9115384615384616
          },
          "final_score": 6.919986661751114
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.12600958467667656,
            "keyword_relevance": 0,
            "conciseness": 0.75
          },
          "final_score": 2.2560575080600596
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8465722037989221,
            "keyword_relevance": 0,
            "conciseness": 0.3692307692307692
          },
          "final_score": 5.817894761255071
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 1.0
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.8340566885702214,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 5.404340131421329
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.8274634130147142,
            "keyword_relevance": 0,
            "conciseness": 0.4923076923076923
          },
          "final_score": 5.949395862703669
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.841633851451419,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 5.449803108708514
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.788888888888889
          },
          "final_score": 4.5777777777777775
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7147919297792062,
            "keyword_relevance": 0.3,
            "conciseness": 0.4
          },
          "final_score": 5.688751578675237
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.8
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7904024292383777,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.409081242096932
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8454139666314965,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.739150466455646
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5949403963591353,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 4.869642378154812
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7137252652734651,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 6.182351591640791
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.48095571421302663,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 4.18573428527816
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5949403963591353,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.269642378154812
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5949403963591353,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.269642378154812
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7476247755406249,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.152415319910416
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5949403963591353,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.269642378154812
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 3.3809523809523814
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7258932177621451,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.355359306572871
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 3.3809523809523814
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5753782199301545,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 4.052269319580927
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.09523809523809523
          },
          "final_score": 1.9904761904761903
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4833333333333334
          },
          "final_score": 2.7666666666666666
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6757048759627196,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.054229255776317
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.6757048759627196,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 4.654229255776317
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7978671301574214,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.787202780944528
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6757048759627196,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.054229255776317
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.6757048759627196,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.054229255776317
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 2.085714285714286
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 4.485714285714286
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.6020009116810324,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.6120054700861943
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.41818181818181815
          },
          "final_score": 3.836363636363636
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.3181818181818182
          },
          "final_score": 2.4363636363636365
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 0.6
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.2727272727272727
          },
          "final_score": 3.5454545454545454
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 1.7999999999999998
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15909090909090912
          },
          "final_score": 3.318181818181818
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.6020009116810324,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.6120054700861943
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.0037284359904917047,
            "rouge_scores": 0.1223947936842281,
            "keyword_relevance": 0.3,
            "readability": 0.4065,
            "coherence": 0.1707251082251082
          },
          "final_score": 2.006696675799656
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.035206054320607236,
            "rouge_scores": 0.1970370343561482,
            "keyword_relevance": 0,
            "readability": 0.3046,
            "coherence": 0.1875
          },
          "final_score": 1.448686177353511
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.010116571264179457,
            "rouge_scores": 0.22539682049009835,
            "keyword_relevance": 0,
            "readability": 0.1294,
            "coherence": 1.0
          },
          "final_score": 2.7298267835085555
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.04505546423412899,
            "rouge_scores": 0.303703699188889,
            "keyword_relevance": 0,
            "readability": 0.5693,
            "coherence": 1.0
          },
          "final_score": 3.8361183268460364
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.28517468278317026,
            "rouge_scores": 0.38076415844334405,
            "keyword_relevance": 0,
            "readability": 0.7825,
            "coherence": 1.0
          },
          "final_score": 4.896877682453028
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.017532201649672802,
            "rouge_scores": 0.053333330005333544,
            "keyword_relevance": 0,
            "readability": 0.6776000000000001,
            "coherence": 1.0
          },
          "final_score": 3.4969310633100132
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.004122003144653969,
            "rouge_scores": 0.24052287235124956,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.4892897509918073
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.016484998771602925,
            "rouge_scores": 0.10565475851243639,
            "keyword_relevance": 0,
            "readability": 0.43189999999999995,
            "coherence": 0.19166666666666665
          },
          "final_score": 1.491412847901412
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0.5,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.9074074074074074,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.62962962962963
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.9232954545454546,
            "coherence": 1.0,
            "keyword_relevance": 0.5
          },
          "final_score": 8.19318181818182
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.8888888888888888,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.555555555555555
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.5371428571428571,
            "coherence": 0.17142857142857143,
            "keyword_relevance": 0
          },
          "final_score": 2.662857142857143
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.8292682926829269,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.3170731707317085
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.9259259259259259,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.703703703703704
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.6785714285714286,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.7142857142857135
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.6561441702951137,
            "coherence": 0.38461538461538464,
            "keyword_relevance": 0
          },
          "final_score": 3.778422835026609
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.8145542213575669,
            "keyword_relevance": 0,
            "conciseness": 0.3166666666666667
          },
          "final_score": 5.520658661478734
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5416666666666666
          },
          "final_score": 2.8833333333333333
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.8316999774634151,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 5.69019986478049
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.55
          },
          "final_score": 2.9000000000000004
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.018798317647335087,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.5185,
            "coherence": 1.0
          },
          "final_score": 3.0745966352946703
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.0204689180374571,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.040937836074915
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.017395797375642234,
            "rouge_scores": 0.08333333020833346,
            "keyword_relevance": 0,
            "readability": 0.4982,
            "coherence": 1.0
          },
          "final_score": 3.1978582551679513
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.003628990737912465,
            "rouge_scores": 0.03174602950113395,
            "keyword_relevance": 0,
            "readability": 0.3832,
            "coherence": 0.0967741935483871
          },
          "final_score": 1.0306984275748672
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.020200106912694155,
            "rouge_scores": 0.06060605738292029,
            "keyword_relevance": 0,
            "readability": 0.5185,
            "coherence": 1.0
          },
          "final_score": 3.1986123285912296
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.002272060090327659,
            "rouge_scores": 0.05860805741979635,
            "keyword_relevance": 0,
            "readability": 0.2377,
            "coherence": 0.1579741379310345
          },
          "final_score": 0.9131085108823169
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.0
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.0038996043298268617,
            "rouge_scores": 0.06896551549346021,
            "keyword_relevance": 0,
            "readability": 0.4799,
            "coherence": 0.20833333333333334
          },
          "final_score": 1.522196906313241
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.647534553847372,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 5.7602073230842326
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.8054342919242277,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.7076057515453655
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.2038407436880897,
            "keyword_relevance": 0,
            "conciseness": 0.375
          },
          "final_score": 1.9730444621285381
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.4993215909890921,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 3.995929545934552
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.4423976819744905,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 3.3543860918469424
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.6375242414564389,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.8251454487386334
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5880173201293322,
            "keyword_relevance": 0,
            "conciseness": 0.825
          },
          "final_score": 5.1781039207759925
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.6375242414564389,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 3.8251454487386334
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.007801364812577689,
            "rouge_scores": 0.10752688038501562,
            "keyword_relevance": 0.3,
            "readability": 0.5215,
            "coherence": 0.10694444444444444
          },
          "final_score": 2.0875453792840752
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.02389319739774052,
            "rouge_scores": 0.2431216907324977,
            "keyword_relevance": 0,
            "readability": 0.5777,
            "coherence": 0.2125
          },
          "final_score": 2.1144297762604767
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.06183522915385178,
            "rouge_scores": 0.273580243136995,
            "keyword_relevance": 0,
            "readability": 0.7977,
            "coherence": 1.0
          },
          "final_score": 4.266230944581694
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.005381887058206485,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.4153,
            "coherence": 0.09090909090909091
          },
          "final_score": 1.023181955934595
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.007735960759051276,
            "rouge_scores": 0.07272727124628102,
            "keyword_relevance": 0.3,
            "readability": 0.6197,
            "coherence": 0.11017543859649122
          },
          "final_score": 2.220677341203647
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.007209845450399489,
            "rouge_scores": 0.054706657860465004,
            "keyword_relevance": 0,
            "readability": 0.39740000000000003,
            "coherence": 0.17565359477124182
          },
          "final_score": 1.2699401961642125
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.0
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.003199708274144278,
            "rouge_scores": 0.08920634725734923,
            "keyword_relevance": 0,
            "readability": 0.6552,
            "coherence": 0.26436781609195403
          },
          "final_score": 2.0239477432468957
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.2
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.55
          },
          "final_score": 2.9000000000000004
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.49368171431211194,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 3.5620902858726717
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 5.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3219839117376566,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.83190347042594
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.7625
          },
          "final_score": 4.525
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.933252427184466,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.733009708737865
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.9492337164750958,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.796934865900384
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.5283738967622158,
            "coherence": 0.14326690821256038,
            "keyword_relevance": 0
          },
          "final_score": 2.543296311686545
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.47094594594594597,
            "coherence": 0.05,
            "keyword_relevance": 0
          },
          "final_score": 2.033783783783784
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.39333057166528584,
            "coherence": 0.11764705882352941,
            "keyword_relevance": 0
          },
          "final_score": 1.9262634631317317
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.8220338983050848,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.288135593220339
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.7545454545454545,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.018181818181818
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.35198019801980196,
            "coherence": 0.1,
            "keyword_relevance": 0
          },
          "final_score": 1.7079207920792077
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3427415091632101,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3564490549792607
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.41923076923076924
          },
          "final_score": 3.838461538461538
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3427415091632101,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3564490549792607
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3427415091632101,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3564490549792607
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4423076923076923
          },
          "final_score": 2.684615384615385
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0.5,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.1116809010012608,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.15384615384615385
          },
          "final_score": 0.5310541096948294
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.004188635776841715,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.0083772715536834
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 9.736901709460828e-05,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.00019473803419
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.01068111996665171,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.43090000000000006,
            "coherence": 0.23529411764705882
          },
          "final_score": 2.353750475227421
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.005582641442640908,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.6234000000000001,
            "coherence": 1.0
          },
          "final_score": 4.257965282885282
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.006638916924097622,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.5,
            "readability": 0.5287,
            "coherence": 1.0
          },
          "final_score": 4.070677833848196
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.0
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.08176983142960487,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.07317073170731707
          },
          "final_score": 0.3098811262738439
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6076923076923078
          },
          "final_score": 3.0153846153846153
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8615384615384616
          },
          "final_score": 3.523076923076923
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.44598472150219837,
            "keyword_relevance": 0,
            "conciseness": 0.6846153846153846
          },
          "final_score": 4.0451390982439595
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3688024992907485,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.512814995744491
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3688024992907485,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.512814995744491
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3688024992907485,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.512814995744491
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.47865039080139826,
            "keyword_relevance": 0,
            "conciseness": 0.46923076923076923
          },
          "final_score": 3.810363883269928
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7961538461538462
          },
          "final_score": 3.3923076923076922
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 1.6
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.1079641913101751,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 1.4477851478610506
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.4120395429545032,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 4.2472372577270185
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.39278480872418275,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.656708852345097
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.12438309700349426,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 1.646298582020966
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.40153821591439587,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 3.2092292954863755
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.1079641913101751,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 1.4477851478610506
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.6970624028357612,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 5.082374417014567
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8482114076610694,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 6.864268445966416
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.46481994092822465,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.088919645569348
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6076923076923078
          },
          "final_score": 3.0153846153846153
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.46481994092822465,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.088919645569348
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.46481994092822465,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.088919645569348
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5692307692307692
          },
          "final_score": 2.9384615384615387
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.46481994092822465,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.088919645569348
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.9,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 5.780952380952381
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.4095238095238095
          },
          "final_score": 5.019047619047619
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8208647546029612,
            "keyword_relevance": 0,
            "conciseness": 0.19047619047619047
          },
          "final_score": 5.306140908570147
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7466670103777433,
            "keyword_relevance": 0.3,
            "conciseness": 0.04999999999999999
          },
          "final_score": 5.18000206226646
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.23809523809523808
          },
          "final_score": 2.276190476190476
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0.3,
            "conciseness": 0.2
          },
          "final_score": 4.0
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.14285714285714285
          },
          "final_score": 3.2857142857142856
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7157622920937254,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 5.594573752562352
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.775
          },
          "final_score": 5.75
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8101860072236698,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 6.636116043342018
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7643060756775446,
            "keyword_relevance": 0.3,
            "conciseness": 0.4
          },
          "final_score": 5.985836454065268
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.775
          },
          "final_score": 4.55
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.9,
            "keyword_relevance": 0,
            "conciseness": 0.675
          },
          "final_score": 6.75
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.7625
          },
          "final_score": 5.725
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 3.55
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.9115384615384616
          },
          "final_score": 4.823076923076924
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.39363654401028236,
            "keyword_relevance": 0,
            "conciseness": 0.4307692307692308
          },
          "final_score": 3.2233577256001555
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 1.0
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 2.2
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4423076923076923
          },
          "final_score": 2.684615384615385
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6192307692307693
          },
          "final_score": 3.0384615384615388
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 2.8000000000000003
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.7777777777777778
          },
          "final_score": 5.755555555555556
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8388888888888889
          },
          "final_score": 3.477777777777778
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 1.5000000000000002
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0.3,
            "conciseness": 0.0
          },
          "final_score": 2.4
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 2.4
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7222222222222222
          },
          "final_score": 3.2444444444444445
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 2.6
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 4.5
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.25
          },
          "final_score": 2.3
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.8308770968530141,
            "keyword_relevance": 0,
            "conciseness": 0.8583333333333334
          },
          "final_score": 6.701929247784752
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 3.3000000000000003
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 4.5
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 4.5
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.718668593328182,
            "keyword_relevance": 0,
            "conciseness": 0.275
          },
          "final_score": 4.862011559969091
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7583333333333333
          },
          "final_score": 3.3166666666666664
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.12503053621822974,
            "rouge_scores": 0.28412698073172504,
            "keyword_relevance": 0,
            "readability": 0.3625,
            "coherence": 0.18055555555555555
          },
          "final_score": 1.904426145011021
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.07832969535832475,
            "rouge_scores": 0.22131147309994578,
            "keyword_relevance": 0.6,
            "readability": 0.6167,
            "coherence": 0.21638655462184875
          },
          "final_score": 3.465455446160239
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.010918663837278684,
            "rouge_scores": 0.09513274177543533,
            "keyword_relevance": 0,
            "readability": 0.7429000000000001,
            "coherence": 0.20459168846265618
          },
          "final_score": 2.107086188150741
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.07223500778803758,
            "rouge_scores": 0.3069403678423181,
            "keyword_relevance": 0.5,
            "readability": 0.6776000000000001,
            "coherence": 0.10344827586206896
          },
          "final_score": 3.32044730298485
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.09238430210261096,
            "rouge_scores": 0.24222221974318517,
            "keyword_relevance": 0,
            "readability": 0.5351,
            "coherence": 0.18973214285714285
          },
          "final_score": 2.118877329405878
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.004604800941813832,
            "rouge_scores": 0.09188033987741075,
            "keyword_relevance": 0.3,
            "readability": 0.5341,
            "coherence": 0.17559523809523808
          },
          "final_score": 2.2123607578289257
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.2777619034011791,
            "rouge_scores": 0.3241830015548892,
            "keyword_relevance": 0,
            "readability": 0.7926000000000001,
            "coherence": 1.0
          },
          "final_score": 4.789089809912137
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.11412271829914293,
            "rouge_scores": 0.28888888452592604,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.8060232056501375
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7993405237556849,
            "keyword_relevance": 0.3,
            "conciseness": 0.5
          },
          "final_score": 6.396043142534108
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.8176329416458457,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.780797649875074
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5294078869880547,
            "keyword_relevance": 0,
            "conciseness": 0.2
          },
          "final_score": 3.576447321928329
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.16239835881086495,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 2.2743901528651893
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6582579987487678,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 5.824547992492606
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5084904799308143,
            "keyword_relevance": 0.3,
            "conciseness": 0.4
          },
          "final_score": 4.450942879584886
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7145489953312121,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.162293971987271
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8489716514775021,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 7.093829908865013
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.00052852710282557,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.0010570542056514
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.44228633548765334,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.45454545454545453
          },
          "final_score": 1.793663580066216
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.8058081183027697,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.6116162366055393
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.03584173751857394,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.7587999999999999,
            "coherence": 0.2222222222222222
          },
          "final_score": 2.0337279194815925
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.00571904112778965,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.7216,
            "coherence": 1.0
          },
          "final_score": 3.4546380822555793
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.13589907155169506,
            "rouge_scores": 0.0,
            "keyword_relevance": 0.3,
            "readability": 0.38659999999999994,
            "coherence": 0.14705882352941177
          },
          "final_score": 1.9391157901622136
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.7748118677050396,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.5496237354100795
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.6891473143102584,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.5555555555555556
          },
          "final_score": 2.4894057397316285
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.14785367648970593,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.0871220589382355
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.14785367648970593,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.0871220589382355
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7346153846153846
          },
          "final_score": 3.2692307692307687
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.10826305346589349,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 0.8495783207953609
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.14785367648970593,
            "keyword_relevance": 0,
            "conciseness": 0.09999999999999998
          },
          "final_score": 1.0871220589382355
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.823076923076923
          },
          "final_score": 3.446153846153846
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.5692307692307692
          },
          "final_score": 5.338461538461539
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494850021680094,
            "keyword_relevance": 0,
            "conciseness": 0.21538461538461534
          },
          "final_score": 5.5276792437772855
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7930183850789652,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.758110310473791
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.810107015474633,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 6.735642092847797
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5455596670635805,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 5.173358002381483
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.5388493626840181,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 4.033096176104109
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7223513421055896,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 4.934108052633538
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.38762312987011815,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 3.625738779220709
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 4.75
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.6536711566087181,
            "keyword_relevance": 0,
            "conciseness": 0.9375
          },
          "final_score": 5.797026939652308
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.010348947228562298,
            "rouge_scores": 0.1645833314451901,
            "keyword_relevance": 0,
            "readability": 0.7141,
            "coherence": 0.45210455977262687
          },
          "final_score": 2.6822736768927586
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.006157652324598362,
            "rouge_scores": 0.18148147890046298,
            "keyword_relevance": 0,
            "readability": 0.2647,
            "coherence": 0.047619047619047616
          },
          "final_score": 0.9999163576882181
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.025520874379338556,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.051041748758677
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.05854960767715713,
            "rouge_scores": 0.34242423852961434,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.13636363636363635
          },
          "final_score": 1.0746749651408156
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.17729842264695017,
            "rouge_scores": 0.35362318483958166,
            "keyword_relevance": 0,
            "readability": 0.3628,
            "coherence": 1.0
          },
          "final_score": 3.787443214973064
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.0028526425171007167,
            "rouge_scores": 0.09039547900794792,
            "keyword_relevance": 0,
            "readability": 0.1422,
            "coherence": 1.0
          },
          "final_score": 2.4708962430500976
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.3655552228545123,
            "rouge_scores": 0.4289044239379269,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 3.5889192935848784
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.015550909644796437,
            "rouge_scores": 0.04827335418047584,
            "keyword_relevance": 0.3,
            "readability": 0.6491,
            "coherence": 0.09303728070175439
          },
          "final_score": 2.2119230890540535
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 4.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4722222222222222
          },
          "final_score": 2.7444444444444445
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7777754140792273,
            "keyword_relevance": 0,
            "conciseness": 0.4722222222222222
          },
          "final_score": 5.611096928919808
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0.3,
            "conciseness": 0.4
          },
          "final_score": 3.2
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.2
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7265223156313984,
            "keyword_relevance": 0,
            "conciseness": 0.7388888888888889
          },
          "final_score": 5.836911671566167
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7466872941786875,
            "keyword_relevance": 0,
            "conciseness": 0.7277777777777779
          },
          "final_score": 5.93567932062768
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 3.5777777777777775
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.0052810813622024685,
            "rouge_scores": 0.18751848116450134,
            "keyword_relevance": 0.3,
            "readability": 0.40009999999999996,
            "coherence": 0.10344827586206896
          },
          "final_score": 1.9926956767775454
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.029703499750112012,
            "rouge_scores": 0.17114213853996663,
            "keyword_relevance": 0.6,
            "readability": 0.5828,
            "coherence": 0.15707671957671956
          },
          "final_score": 3.0814447157335962
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.013940187832502561,
            "rouge_scores": 0.27160493344307274,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.5710902425511506
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.004928412630671679,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.2207,
            "coherence": 0.08
          },
          "final_score": 0.6112568252613435
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.004516694634971784,
            "rouge_scores": 0.2028218651663927,
            "keyword_relevance": 0,
            "readability": 0.0282,
            "coherence": 0.1431818181818182
          },
          "final_score": 0.7574407559663654
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.0020632861907783676,
            "rouge_scores": 0.0,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.0041265723815567
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.09242683479084891,
            "rouge_scores": 0.23451909993907108,
            "keyword_relevance": 0,
            "readability": 0.051500000000000004,
            "coherence": 1.0
          },
          "final_score": 2.7568918694598397
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.004500229728607774,
            "rouge_scores": 0.16671354586404344,
            "keyword_relevance": 0.8,
            "readability": 0.5215,
            "coherence": 0.1597690459583043
          },
          "final_score": 3.3049656431019114
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.17801292859656137,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 2.3680775715793683
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.17801292859656137,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.7680775715793682
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.2684491633460847,
            "keyword_relevance": 0,
            "conciseness": 0.21250000000000002
          },
          "final_score": 2.0356949800765083
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.3
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.17801292859656137,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.7680775715793682
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.8494850021680094,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 5.7969100130080555
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.6937714543195939,
            "keyword_relevance": 0,
            "conciseness": 0.7625
          },
          "final_score": 5.687628725917563
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.875
          },
          "final_score": 3.55
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.40435245925142105,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.7261147555085263
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 3.9000000000000004
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8730769230769231
          },
          "final_score": 3.546153846153846
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.40435245925142105,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.7261147555085263
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.40435245925142105,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.7261147555085263
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.6846153846153846
          },
          "final_score": 3.169230769230769
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.85
          },
          "final_score": 3.5
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3579516485661266,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.4477098913967597
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3579516485661266,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.4477098913967597
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7846153846153846
          },
          "final_score": 3.3692307692307693
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3579516485661266,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.4477098913967597
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3579516485661266,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.4477098913967597
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3579516485661266,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.4477098913967597
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7961538461538462
          },
          "final_score": 3.3923076923076922
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.3807692307692308
          },
          "final_score": 2.5615384615384618
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 3.7
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.46923076923076923
          },
          "final_score": 2.7384615384615385
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 0.8999999999999999
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7346153846153846
          },
          "final_score": 3.2692307692307687
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.7022350321750611,
            "keyword_relevance": 0,
            "conciseness": 0.5961538461538461
          },
          "final_score": 5.405717885358059
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.3423076923076923
          },
          "final_score": 3.6846153846153844
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.7461538461538462
          },
          "final_score": 3.292307692307692
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 6.2
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.4722222222222222
          },
          "final_score": 3.944444444444444
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.6674508392176349,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 4.004705035305809
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.3
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 5.988888888888888
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 2.6
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 5.977777777777778
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8331699224989351,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.665686201660277
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.05922623086844013,
            "rouge_scores": 0.14161219819841372,
            "keyword_relevance": 0,
            "readability": 0.4156,
            "coherence": 0.1835016835016835
          },
          "final_score": 1.5998802251370747
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.0525926280436685,
            "rouge_scores": 0.23927251819017556,
            "keyword_relevance": 0,
            "readability": 0.2241,
            "coherence": 0.14285714285714285
          },
          "final_score": 1.317644578181974
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.030353198426271925,
            "rouge_scores": 0.13860013573074756,
            "keyword_relevance": 0,
            "readability": 0.1344,
            "coherence": 0.08695652173913043
          },
          "final_score": 0.7806197117922998
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.004875806249463946,
            "rouge_scores": 0.08080807954392409,
            "keyword_relevance": 0,
            "readability": 0.5676,
            "coherence": 0.11503267973856209
          },
          "final_score": 1.5366331310639003
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.031444344038777564,
            "rouge_scores": 0.12024086861428751,
            "keyword_relevance": 0.3,
            "readability": 0.615,
            "coherence": 0.3411330049261084
          },
          "final_score": 2.8156364351583467
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.006095294343094757,
            "rouge_scores": 0.1251437754715174,
            "keyword_relevance": 0,
            "readability": 0.4156,
            "coherence": 0.13513986013986012
          },
          "final_score": 1.3639578599089446
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.23462350320528,
            "rouge_scores": 0.4289044239379269,
            "keyword_relevance": 0,
            "readability": 0.5693,
            "coherence": 1.0
          },
          "final_score": 4.465655854286414
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.07772174600740504,
            "rouge_scores": 0.1795976976922625,
            "keyword_relevance": 0,
            "readability": 0.6234000000000001,
            "coherence": 0.15555555555555556
          },
          "final_score": 2.0725499985104463
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7661472025892113,
            "keyword_relevance": 0,
            "conciseness": 0.95
          },
          "final_score": 6.496883215535267
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 4.7749999999999995
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 2.7
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 1.4000000000000001
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.6154602523335977,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 4.492761514001586
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.8384099381871916,
            "keyword_relevance": 0,
            "conciseness": 0.5
          },
          "final_score": 6.03045962912315
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.6154602523335977,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 4.492761514001586
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8875
          },
          "final_score": 3.5749999999999997
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0.5,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.8511627906976744,
            "coherence": 1.0,
            "keyword_relevance": 0.5
          },
          "final_score": 7.904651162790698
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.9343137254901961,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.737254901960785
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.41787439613526567,
            "coherence": 0.4444444444444444,
            "keyword_relevance": 0
          },
          "final_score": 3.004830917874396
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.5484590849412033,
            "coherence": 0.18585526315789475,
            "keyword_relevance": 0.5
          },
          "final_score": 4.251402129238498
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.8260869565217391,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.304347826086957
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.6992753623188406,
            "coherence": 0.5,
            "keyword_relevance": 0
          },
          "final_score": 4.297101449275362
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.7463768115942029,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.985507246376811
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.9492753623188406,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.797101449275362
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.020484417607671643,
            "rouge_scores": 0.2735632148826001,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.16666666666666666
          },
          "final_score": 0.9214285983138768
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.00458211488848427,
            "rouge_scores": 0.07997377779725799,
            "keyword_relevance": 0.3,
            "readability": 0.6035,
            "coherence": 0.11258169934640523
          },
          "final_score": 2.2012751840642952
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.008930983713298183,
            "rouge_scores": 0.12074829704931977,
            "keyword_relevance": 0.3,
            "readability": 0.7084,
            "coherence": 0.10664335664335664
          },
          "final_score": 2.489445274811949
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.07451835561685542,
            "rouge_scores": 0.25798211645728436,
            "keyword_relevance": 0,
            "readability": 0.5794,
            "coherence": 0.2638888888888889
          },
          "final_score": 2.3515787219260575
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.0035995604555567853,
            "rouge_scores": 0.12612612317506702,
            "keyword_relevance": 0,
            "readability": 0.3036,
            "coherence": 0.13793103448275862
          },
          "final_score": 1.1425134362267648
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.10046152640557755,
            "rouge_scores": 0.21120447869052564,
            "keyword_relevance": 0,
            "readability": 0.8265,
            "coherence": 0.08695652173913043
          },
          "final_score": 2.4502450536704674
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.3050975216056289,
            "rouge_scores": 0.39682539182539683,
            "keyword_relevance": 0,
            "readability": 0.2207,
            "coherence": 1.0
          },
          "final_score": 3.8452458268620515
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.04729181034073558,
            "rouge_scores": 0.12922705069070314,
            "keyword_relevance": 0,
            "readability": 0.7121,
            "coherence": 0.12777777777777777
          },
          "final_score": 2.032793277618433
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.8976608187134503,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.590643274853801
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.7554347826086957,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.021739130434782
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.8771929824561404,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.508771929824562
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.4305555555555556,
            "coherence": 0.08333333333333333,
            "keyword_relevance": 0
          },
          "final_score": 1.9722222222222223
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.2890974729241877,
            "coherence": 0.08,
            "keyword_relevance": 0
          },
          "final_score": 1.3963898916967508
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.4219924812030075,
            "coherence": 0.10714285714285714,
            "keyword_relevance": 0
          },
          "final_score": 2.0093984962406015
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.8918128654970761,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.567251461988304
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.8771929824561404,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.508771929824562
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5,
            "keyword_relevance": 0,
            "conciseness": 1.0
          },
          "final_score": 5.0
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.6191164277242185,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 4.414698566345311
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 3.5888888888888886
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.7446595049232495,
            "keyword_relevance": 0.3,
            "conciseness": 0.3
          },
          "final_score": 5.6679570295394965
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.4
          },
          "final_score": 5.0
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.5098682135395338,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 4.359209281237203
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.7833333333333334
          },
          "final_score": 5.766666666666667
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.844337267010377,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.732690268728929
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.957286432160804,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.829145728643216
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.7355555555555555,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.942222222222222
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.9472361809045227,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.788944723618091
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.44526202440775303,
            "coherence": 0.07142857142857142,
            "keyword_relevance": 0
          },
          "final_score": 1.9953338119167265
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.8438818565400844,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.375527426160338
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.48055414336553126,
            "coherence": 0.07142857142857142,
            "keyword_relevance": 0
          },
          "final_score": 2.1365022877478395
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.9045226130653266,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.618090452261307
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.7534246575342466,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.013698630136987
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3353897259606279,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3123383557637673
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.3353897259606279,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3123383557637673
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5192307692307692
          },
          "final_score": 2.8384615384615386
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.3326922100172748,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.2961532601036487
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.3353897259606279,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3123383557637673
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.3353897259606279,
            "keyword_relevance": 0,
            "conciseness": 0.15000000000000002
          },
          "final_score": 2.3123383557637673
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.4423076923076923
          },
          "final_score": 2.684615384615385
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.5307692307692308
          },
          "final_score": 2.8615384615384616
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0.3,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.5526355103120955,
            "keyword_relevance": 0,
            "conciseness": 0.9444444444444444
          },
          "final_score": 5.204701950761461
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.5193239675800755,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 3.7159438054804528
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.29788764523296696,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 3.57621476028669
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0.3,
            "conciseness": 0.35
          },
          "final_score": 1.9
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.1,
            "keyword_relevance": 0,
            "conciseness": 0.35
          },
          "final_score": 1.3
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.4050793029640215,
            "keyword_relevance": 0,
            "conciseness": 0.0
          },
          "final_score": 2.430475817784129
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.41868236189671937,
            "keyword_relevance": 0,
            "conciseness": 0.7277777777777779
          },
          "final_score": 3.967649726935872
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.5136711234568572,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 4.74869340740781
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.8507462686567164,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.402985074626866
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.7465753424657534,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.986301369863014
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.95,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.799999999999999
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.9664351851851851,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.8657407407407405
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.835820895522388,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.343283582089551
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.9215686274509804,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.686274509803923
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.8507462686567164,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.402985074626866
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.530236634531113,
            "coherence": 0.42857142857142855,
            "keyword_relevance": 0
          },
          "final_score": 3.4066608238387373
        }
      }
    },
    {
      "question_type": "generate",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "creativity": 0.7605633802816901,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.042253521126762
        },
        "Mistral": {
          "criteria_scores": {
            "creativity": 0.7676056338028169,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.070422535211268
        },
        "Phi-3": {
          "criteria_scores": {
            "creativity": 0.9242424242424243,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.696969696969697
        },
        "Gemma": {
          "criteria_scores": {
            "creativity": 0.5581081081081081,
            "coherence": 0.4,
            "keyword_relevance": 0
          },
          "final_score": 3.4324324324324325
        },
        "Gemma2": {
          "criteria_scores": {
            "creativity": 0.7764227642276422,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.105691056910569
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "creativity": 0.8631921824104234,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 6.452768729641694
        },
        "MistralNemo": {
          "criteria_scores": {
            "creativity": 0.7180851063829787,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.872340425531915
        },
        "Llama3.1": {
          "criteria_scores": {
            "creativity": 0.7218543046357616,
            "coherence": 1.0,
            "keyword_relevance": 0
          },
          "final_score": 5.887417218543046
        }
      }
    },
    {
      "question_type": "numeric",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0.3,
            "conciseness": 0.5
          },
          "final_score": 5.8
        },
        "Mistral": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.5777777777777777
          },
          "final_score": 5.355555555555556
        },
        "Phi-3": {
          "criteria_scores": {
            "numeric_accuracy": 0.3,
            "keyword_relevance": 0,
            "conciseness": 0.8944444444444444
          },
          "final_score": 3.5888888888888886
        },
        "Gemma": {
          "criteria_scores": {
            "numeric_accuracy": 0.321264912885877,
            "keyword_relevance": 0,
            "conciseness": 0.3
          },
          "final_score": 2.527589477315262
        },
        "Gemma2": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.45
          },
          "final_score": 5.1
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "numeric_accuracy": 0.33930125329989946,
            "keyword_relevance": 0.3,
            "conciseness": 0.5
          },
          "final_score": 3.6358075197993966
        },
        "MistralNemo": {
          "criteria_scores": {
            "numeric_accuracy": 0.7,
            "keyword_relevance": 0,
            "conciseness": 0.8888888888888888
          },
          "final_score": 5.977777777777778
        },
        "Llama3.1": {
          "criteria_scores": {
            "numeric_accuracy": 0.8387854693074634,
            "keyword_relevance": 0,
            "conciseness": 0.8333333333333334
          },
          "final_score": 6.699379482511447
        }
      }
    },
    {
      "question_type": "descriptive",
      "keyword_score": 0,
      "model_scores": {
        "Llama3": {
          "criteria_scores": {
            "bleu_score": 0.05106973167304378,
            "rouge_scores": 0.19982078482530632,
            "keyword_relevance": 0,
            "readability": 0.599,
            "coherence": 0.1706845238095238
          },
          "final_score": 2.041150080615748
        },
        "Mistral": {
          "criteria_scores": {
            "bleu_score": 0.10281773108047429,
            "rouge_scores": 0.43169398481809956,
            "keyword_relevance": 0,
            "readability": 0.5564,
            "coherence": 0.36095673967527514
          },
          "final_score": 2.9037369111476985
        },
        "Phi-3": {
          "criteria_scores": {
            "bleu_score": 0.04701040821391918,
            "rouge_scores": 0.21621621130752386,
            "keyword_relevance": 0,
            "readability": 0.5861999999999999,
            "coherence": 1.0
          },
          "final_score": 3.6988532390428865
        },
        "Gemma": {
          "criteria_scores": {
            "bleu_score": 0.03639075626321298,
            "rouge_scores": 0.21752136270839373,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 0.0772005772005772
          },
          "final_score": 0.6622253923443678
        },
        "Gemma2": {
          "criteria_scores": {
            "bleu_score": 0.12740810460323607,
            "rouge_scores": 0.2962962914677641,
            "keyword_relevance": 0,
            "readability": 0.5743,
            "coherence": 0.07142857142857142
          },
          "final_score": 2.1388659349991435
        },
        "Phi-3 Medium": {
          "criteria_scores": {
            "bleu_score": 0.012430185041026947,
            "rouge_scores": 0.07407407275720167,
            "keyword_relevance": 0,
            "readability": 0.0,
            "coherence": 1.0
          },
          "final_score": 2.1730085155964574
        },
        "MistralNemo": {
          "criteria_scores": {
            "bleu_score": 0.0076464605606061916,
            "rouge_scores": 0.16842104961181906,
            "keyword_relevance": 0,
            "readability": 1.0,
            "coherence": 1.0
          },
          "final_score": 4.352135020344851
        },
        "Llama3.1": {
          "criteria_scores": {
            "bleu_score": 0.02432091744873396,
            "rouge_scores": 0.13067150383022283,
            "keyword_relevance": 0.3,
            "readability": 0.5811,
            "coherence": 0.2106060606060606
          },
          "final_score": 2.4933969637700346
        }
      }
    }
  ],
  "model_total_scores": {
    "Llama3": 398.46013806243405,
    "Mistral": 399.4697773466543,
    "Phi-3": 375.6831730537453,
    "Gemma": 304.6922254625981,
    "Gemma2": 360.6390156020192,
    "Phi-3 Medium": 333.9905692481923,
    "MistralNemo": 428.96097302007576,
    "Llama3.1": 353.9082132846239
  },
  "model_average_scores": {
    "Llama3": 3.9846013806243405,
    "Mistral": 3.994697773466543,
    "Phi-3": 3.756831730537453,
    "Gemma": 3.046922254625981,
    "Gemma2": 3.6063901560201916,
    "Phi-3 Medium": 3.339905692481923,
    "MistralNemo": 4.289609730200757,
    "Llama3.1": 3.539082132846239
  },
  "model_type_scores": {
    "Llama3": {
      "numeric": 4.067231249621744,
      "descriptive": 2.126616387863027,
      "generate": 6.715734331079553
    },
    "Mistral": {
      "numeric": 4.140029898392705,
      "descriptive": 2.1405648938419657,
      "generate": 6.405800483585027
    },
    "Phi-3": {
      "numeric": 3.738434759420351,
      "descriptive": 2.48705824580605,
      "generate": 5.99766402182225
    },
    "Gemma": {
      "numeric": 3.236302900869459,
      "descriptive": 2.0760460500802527,
      "generate": 3.743040292639824
    },
    "Gemma2": {
      "numeric": 3.5933517889603706,
      "descriptive": 2.9143329507093516,
      "generate": 4.842755723383803
    },
    "Phi-3 Medium": {
      "numeric": 3.3502977318998415,
      "descriptive": 2.086354538870953,
      "generate": 5.409339755349349
    },
    "MistralNemo": {
      "numeric": 4.206310747904542,
      "descriptive": 3.41235821699502,
      "generate": 6.190684125568479
    },
    "Llama3.1": {
      "numeric": 3.9685590728369458,
      "descriptive": 1.932470053642704,
      "generate": 4.110579413083295
    }
  },
  "model_criteria_scores": {
    "Llama3": {
      "numeric_accuracy": 0.4864086373198735,
      "keyword_relevance": 0.060999999999999985,
      "conciseness": 0.5420820205435588,
      "bleu_score": 0.04324048630689406,
      "rouge_scores": 0.12148422686619878,
      "readability": 0.4472409090909091,
      "coherence": 0.5694153307624358,
      "creativity": 0.8712412750775802
    },
    "Mistral": {
      "numeric_accuracy": 0.5190331842090368,
      "keyword_relevance": 0.026000000000000002,
      "conciseness": 0.508300011953858,
      "bleu_score": 0.09249807439911852,
      "rouge_scores": 0.17374677048599016,
      "readability": 0.28441363636363637,
      "coherence": 0.6466207784225493,
      "creativity": 0.8226039670501026
    },
    "Phi-3": {
      "numeric_accuracy": 0.4524333838797008,
      "keyword_relevance": 0.009,
      "conciseness": 0.5073018434556895,
      "bleu_score": 0.10192919137334581,
      "rouge_scores": 0.10528322952704029,
      "readability": 0.42770454545454534,
      "coherence": 0.6964908227632872,
      "creativity": 0.8308941966484272
    },
    "Gemma": {
      "numeric_accuracy": 0.41171222913998884,
      "keyword_relevance": 0.087,
      "conciseness": 0.29686091686091676,
      "bleu_score": 0.04478185605248294,
      "rouge_scores": 0.12258146153896586,
      "readability": 0.4252772727272728,
      "coherence": 0.35025832718320077,
      "creativity": 0.6149546181095065
    },
    "Gemma2": {
      "numeric_accuracy": 0.4691977772479257,
      "keyword_relevance": 0.025,
      "conciseness": 0.3721594858133318,
      "bleu_score": 0.13213716344883228,
      "rouge_scores": 0.1980526192135228,
      "readability": 0.4541363636363636,
      "coherence": 0.6524713695548063,
      "creativity": 0.666419083046691
    },
    "Phi-3 Medium": {
      "numeric_accuracy": 0.4217573586910439,
      "keyword_relevance": 0.05299999999999999,
      "conciseness": 0.3652614052614051,
      "bleu_score": 0.044284537447350954,
      "rouge_scores": 0.08778164741156971,
      "readability": 0.29493636363636366,
      "coherence": 0.6134508264462654,
      "creativity": 0.7572425312449299
    },
    "MistralNemo": {
      "numeric_accuracy": 0.4947295167259185,
      "keyword_relevance": 0.0,
      "conciseness": 0.6189668237745158,
      "bleu_score": 0.2028591695414822,
      "rouge_scores": 0.15770024198633067,
      "readability": 0.4077409090909091,
      "coherence": 0.9609523809523809,
      "creativity": 0.7976710313921195
    },
    "Llama3.1": {
      "numeric_accuracy": 0.4683419044394989,
      "keyword_relevance": 0.043,
      "conciseness": 0.5746384384845924,
      "bleu_score": 0.06591160583588615,
      "rouge_scores": 0.08952837919630396,
      "readability": 0.37861363636363626,
      "coherence": 0.36294765146580443,
      "creativity": 0.6125384946972705
    }
  }
}