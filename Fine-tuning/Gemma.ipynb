{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":41407,"status":"ok","timestamp":1718011789226,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"oCle1x2zR_Ut"},"outputs":[],"source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415,"referenced_widgets":["3f7e583841c64e0a9ead18873e2af587","9fe90894dde6465d95497d05729feb11","a3cd2bb2c6c54ace9518fd332c0b3c05","1f94f0985be64e04858d609e2a6f6ebe","ad5e9d0de533489d8c4219e53d935170","da35870559734bfda0e8e7a8a822d340","54efd9ad54e74507bbaceb98b03a96b2","76aafe9a90b5419a9426cf5c8ddf7c65","28f03c0eda6b4efda75b035280ac24d0","2d5b2646435f443b997ace484f3f19a5","2aa02489e64249a7b3350b9e103bdc6b","0fd30080ad3242caa94ab7c215473f4b","400dea62d49641ae8d27c3da2a649f94","4caa1b72cf5c4648ab768aa27bfcec39","37e8249ff869499a8c742627fd8002e5","8d00abe3071642188ebb666506c7ff5b","d07d380653fc42f78b3874760c3718ab","19f7340a18cb449dba3ffd042818332a","6c06637de3bb45b9ac7c9c5a2d461a22","1f0b3f6c74f743669c5765745ca47103","ebfa7d36c60b4fbfa0222f3c8c3add75","218eaa83ae3b4a8c96df3b6d58d75b49","f9c4d72cfa724983b19b073225db3cd3","c8135a01d5b9447dbff0971545b94176","5804ab1d00c84aa8b22e4718cecd49f5","c29e6d15833f4a91ba46641e1231bfd0","9aed71e59cfd46e1a7cd100b177c1413","ef1374654a1d4cee9effdb9d9adef11e","1d2a1e09fbd442f2932f7c4e65d0b66d","5273b4cf4df5449d952c8e900cc8794c","3b095a293fb546319557b3e712722335","9aa1208a920c47fb82cc7b90294b08d5","965b06fc492240719d08ce5adaf5fc95","9ef51230979a4e09adf703924721f976","8f1ccafe693d4b1e99ab75dd9cd18523","c43deac2bebc42e1bede0c8e38cb94ad","1c25a5f4d47e47048e36ca4beff7ae62","edb817f7eedc4316b888358f33f5db36","ee7094c276b344538c80fb249589d38c","49e630a28f2d4131a49c580e40f17ea0","e1e1417050ab4d70a15234c10f518153","bcc5405d47b340709ff37a1c4dae3fcf","0c39b4a0075144ed9888de66ce73d120","11b73034e19040f3b784c446c0734bd4","392db96ab8a74fbf8c47c0e873cbfae6","8cfc27144cfe4aaa877f26d49709c45d","c1f8ebcf7ed244c0b562068d2418e975","3d319100c7d740369971bca41ceaecf4","476385dfd4274a8f893be9ef3f604836","5b9d1352d3e5481eb706145a8d2ee2a2","d49e122514da458abce86544fda5332b","42b4c98ac5744d868b44004f06d120d8","716d66e6ed434183aa683fe9783cbd05","ae863ed04ccc47279a94696ebaac4985","f312007d7c234feaa1068aac1abbab94","8ddcf52acd6c4561a5061f8bf5986147","286b139391bb42dba2f76de995a874fe","4f7afac6fc0b4740b65898ebc8706480","09bc7494dc9f4c8f981303ed900557c6","18e836f6c3eb477f968aa2610dd659d6","f769c713a27a4b8cb7bfe396ebe1a023","d293bb1e11684df881774b33bca76be0","cf4d92e7cbc6493c9a7fa62b72651c46","c3c91e82dfef4fca984afa36ba016985","e99feb2faa274d2786e789ed35cf5969","51fe1761ac204821be9f49bb0e206722","986a7b84deed46dc9d43c0a8763c7e28","b5ff59d50db24302bfbf9db2fb0ec0ec","5bdd09119f5444808df648202d962838","1b02b1fd93ed4dd2b2daadea57d68375","302ff71e24254e388f1cdaba8d0bb20b","bc1fe363fdbe428cb3117309f3cc4e13","2a1eab57817442eb8697384c447a3b0c","9b51e582d030404db44e323598507712","7746eb8e2bed47119bfeaaf335bb2760","f3f0490659f14bc5b665c99dc1eec054","817985f8873d4df794671abdcca5d639"]},"executionInfo":{"elapsed":39919,"status":"ok","timestamp":1718011833324,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"VAz54uISSHzp","outputId":"d0b662e0-c857-4790-c589-3c42783bcfc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f7e583841c64e0a9ead18873e2af587","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth: Fast Gemma patching release 2024.5\n","   \\\\   /|    GPU: NVIDIA L4. Max memory: 22.168 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fd30080ad3242caa94ab7c215473f4b","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/5.57G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9c4d72cfa724983b19b073225db3cd3","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ef51230979a4e09adf703924721f976","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"392db96ab8a74fbf8c47c0e873cbfae6","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ddcf52acd6c4561a5061f8bf5986147","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"986a7b84deed46dc9d43c0a8763c7e28","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    \"unsloth/llama-2-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-it-bnb-4bit\", # Instruct version of Gemma 7b\n","    \"unsloth/gemma-2b-bnb-4bit\",\n","    \"unsloth/gemma-2b-it-bnb-4bit\", # Instruct version of Gemma 2b\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/gemma-7b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3244,"status":"ok","timestamp":1718011839056,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"r8OFBighSLvL","outputId":"b2a0738e-f2ad-43aa-b72a-e14650b5205e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth 2024.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["cc4d682d38924b109d1191f2e9db34c9","7fba1d2debb04e6da87906fb2a15b162","eaf0574f20e44503b876687801109319","bf6078095fc34928a48e2a6a8bbe6d08","95905e7cb1be47e58ef2e657eff8ef4b","e0fe8595ec7e423fb64a149fb9794258","18e948755d1c429c8ed090847d8dfb39","070648f8d48d40ab9bcd1f6bceca0c8d","c80b88a3c4c244f5a9b7b2b47d106c24","c40337f6e6234c92b520e4191bb20153","10129f9f8b754395aea0017abc983660","9d8258e8950846d3b1cc95943084626e","38f7412531f1447d8b343c1c1edc80bc","b785ea153c334d6fa381a6572943be6b","1d2bb242f6564ed698acb585ab184a51","cb7ea8881a634fcb9df3823795b4d6bd","650ea41435844cfcb2b4d64898b96e2b","efda3bc6544d45f794392a35b0710448","5775e9abe7894acabd1c404cfeaa9a83","1e82eee799674205ba7b232c20fa2d48","16d54e6275364fc0ae11f60bf3910829","b3b54eec74084e03b203ca0fdd47f50c","456a2dc089fd437cb94408973e2cd105","c4a6d4efec544181ba8d149a9aadb969","e5ba232023fb413f9f6ba19c711d169e","9d582ac8dc3548f381d8b6154db1b43f","223a6b33e00e479390a52d1619f3ea10","8f3d15b379e3431ba25f00c81c6f5d88","0f59246f099144d5b5a801541e5cceb4","d7f1d7cc51de41a7b17a974d00fcd8da","9b8ca62dc9964fd5b81a2f89a3fc0b3f","ceb60498584140ddbf624a57974f5b52","c8acb54a0ea34c328b94f1292a582d03","a06c7694e10945fbae365991ce34d4bc","982f3b89e6ef49498b34a689d3981458","09bab0c9b838403fa382a1e15125437d","ac54531bb5844cfd9fa93ab4c6695a2a","61f3e93d4983449c97d50a0c0094d04b","dd9e2e85e9d54c359129faf5e76eb37e","96c96f1a441243e097a0d3005066e3ee","cbe2f9db53cf4776b4a91c1c6e811845","95bdd8d09f154c59abef56f5f5c3368a","322ec14b0e734cf28fb6750fadfb8d69","929521bfb14c4439b14873fb897d431b"]},"executionInfo":{"elapsed":30086,"status":"ok","timestamp":1718011871975,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"8Ctusfi_SPJb","outputId":"d279d2aa-a0aa-4968-cd74-c24bd32693b0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc4d682d38924b109d1191f2e9db34c9","version_major":2,"version_minor":0},"text/plain":["Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d8258e8950846d3b1cc95943084626e","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0/17 [00:00<?, ?files/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"456a2dc089fd437cb94408973e2cd105","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/1720313 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a06c7694e10945fbae365991ce34d4bc","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1720313 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"KANGYONGMA/GVIMJ\", split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["d14001408bf64ba4ac2301f595e9a976","9004f0c84f5d43b5bc40d5e567949d92","f15a56ad68eb43d3814825227c0d7c0d","d75205aa75e3435cb5b7bf88976aea7e","e4cc39642b514579bbc50a9ce2014133","60807a58b44e4a7dba7f3a2961ff2895","4c47aab1823d4f6aa250f2ff548c7f7b","4efd5890664748e8a631a38a96cdcbef","af2b28af5c4748f09e36cb0537146bb5","3b1ea9d4527d4527b806e078c74b5af7","65430c69598d47cb8502eac2c564e4d0"]},"executionInfo":{"elapsed":275554,"status":"ok","timestamp":1718012151447,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"k_iKRTzqSkvE","outputId":"caa60f35-11e9-449d-c498-d6019387d284"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d14001408bf64ba4ac2301f595e9a976","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=2):   0%|          | 0/1720313 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":278530,"status":"ok","timestamp":1718012432856,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"lQfCNgx1TPKd","outputId":"76689243-a296-4b11-89d4-09eb79484866"},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 1,720,313 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 50,003,968\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 04:22, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.949400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.857600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.204900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.861100</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.664100</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.877800</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.421400</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.441300</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.144400</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.117000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.109000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.046500</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.935700</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.851800</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.866400</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.925000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.809600</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.783600</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.843600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.783400</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.770100</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.899200</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.812400</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.755900</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.636600</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.676100</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.780300</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.758200</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.687000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.686000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.653200</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.718400</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.800300</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.597900</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.655200</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.748500</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.611000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.786600</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.638500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.636100</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.700300</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.715800</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.651700</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.641500</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.714600</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.744700</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.612500</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.609700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.674000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.491200</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.621000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.664300</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.616700</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.684200</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.538900</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.678600</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.635700</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.648700</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.618800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.736400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9198,"status":"ok","timestamp":1718012449574,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"TAOoxUd5TRkY","outputId":"640f2181-354f-4347-dca8-01d004786842"},"outputs":[{"name":"stdout","output_type":"stream","text":["<bos>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Provided the product below, propose some possible reactants that could have been used in the reaction.\n","\n","### Input:\n","[C][O][C][=C][C][=C][C][Branch2][Ring2][Branch1][C][C][C][Branch1][C][C][Branch1][C][C][C][=C][C][Branch1][=C][C][=Branch1][C][=O][N][S][Branch1][C][C][=Branch1][C][=O][=O][=C][C][=C][Ring1][=N][N][Ring2][Ring1][Ring1][=C][Ring2][Ring1][=Branch2]\n","\n","### Response:\n","[C][O][C][=C][C][=C][C][Branch2][Ring2][Branch1][C][C][C][Branch1][C][C][Branch1][C][C][C][=C][C][Branch1][=C][C][=Branch1][C][=O][N][S][Branch1][C][C][=Branch1][C][=O][=O][=C][C][=C][Ring1][=N][N][Ring2][Ring1][Ring1][=C][Ring2][Ring1][=Branch2]<eos>\n"]}],"source":["\n","FastLanguageModel.for_inference(model)\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Provided the product below, propose some possible reactants that could have been used in the reaction.\", # instruction\n","        \"[C][O][C][=C][C][=C][C][Branch2][Ring2][Branch1][C][C][C][Branch1][C][C][Branch1][C][C][C][=C][C][Branch1][=C][C][=Branch1][C][=O][N][S][Branch1][C][C][=Branch1][C][=O][=O][=C][C][=C][Ring1][=N][N][Ring2][Ring1][Ring1][=C][Ring2][Ring1][=Branch2]\", # input\n","        \"\", # output\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":844,"status":"ok","timestamp":1718012452796,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"Q102f4eFTpb-"},"outputs":[],"source":["model.save_pretrained(\"lora_model\") # Local saving"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355873,"status":"ok","timestamp":1718012810356,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"P9erKczET0er","outputId":"c5bcc852-6d10-400b-e852-9bc6c816304e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 5.6G\n"]},{"name":"stdout","output_type":"stream","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 34.94 out of 52.96 RAM for saving.\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 23/28 [00:01<00:00, 13.34it/s]We will save to Disk and not RAM now.\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:06<00:00,  4.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n","Done.\n"]},{"name":"stderr","output_type":"stream","text":["Unsloth: Converting gemma model. Can use fast conversion = False.\n","Unsloth: We must use f16 for non Llama and Mistral models.\n"]},{"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GUUF 16bits will take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to q4_k_m will take 20 minutes.\n"," \"-____-\"     In total, you will have to wait around 26 minutes.\n","\n","Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n","Unsloth: [1] Converting model at model into f16 GGUF format.\n","The output location will be ./model-unsloth.F16.gguf\n","This will take 3 minutes...\n","INFO:hf-to-gguf:Loading model: model\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:gguf.vocab:Setting special token type bos to 2\n","INFO:gguf.vocab:Setting special token type eos to 1\n","INFO:gguf.vocab:Setting special token type unk to 3\n","INFO:gguf.vocab:Setting special token type pad to 0\n","INFO:gguf.vocab:Setting add_bos_token to True\n","INFO:gguf.vocab:Setting add_eos_token to False\n","INFO:gguf.vocab:Setting special token type prefix to 67\n","INFO:gguf.vocab:Setting special token type suffix to 69\n","INFO:gguf.vocab:Setting special token type middle to 68\n","WARNING:gguf.vocab:No handler for special token type fsep with id 70 - skipping\n","INFO:gguf.vocab:Setting special token type eot to 107\n","INFO:hf-to-gguf:Exporting model to 'model-unsloth.F16.gguf'\n","INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n","INFO:hf-to-gguf:token_embd.weight,         torch.bfloat16 --> F16, shape = {3072, 256000}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.10.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.11.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.12.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.13.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.14.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.15.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.16.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.17.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.18.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.19.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.20.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.21.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.22.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.23.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.24.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.25.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.26.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.bfloat16 --> F16, shape = {24576, 3072}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3072, 24576}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.27.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 3072}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,      torch.bfloat16 --> F16, shape = {3072, 4096}\n","INFO:hf-to-gguf:output_norm.weight,        torch.bfloat16 --> F32, shape = {3072}\n","Writing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.1G/17.1G [01:25<00:00, 200Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to 'model-unsloth.F16.gguf'\n","Unsloth: Conversion completed! Output location: ./model-unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n","main: build = 3120 (af4ae502)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing './model-unsloth.F16.gguf' to './model-unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n","llama_model_loader: loaded meta data with 28 key-value pairs and 254 tensors from ./model-unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = gemma\n","llama_model_loader: - kv   1:                               general.name str              = model\n","llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192\n","llama_model_loader: - kv   3:                     gemma.embedding_length u32              = 3072\n","llama_model_loader: - kv   4:                          gemma.block_count u32              = 28\n","llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 24576\n","llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 16\n","llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 16\n","llama_model_loader: - kv   8:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv   9:                 gemma.attention.key_length u32              = 256\n","llama_model_loader: - kv  10:               gemma.attention.value_length u32              = 256\n","llama_model_loader: - kv  11:                          general.file_type u32              = 1\n","llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = default\n","llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n","llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,256000]  = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 2\n","llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 1\n","llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 3\n","llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n","llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  23:             tokenizer.ggml.prefix_token_id u32              = 67\n","llama_model_loader: - kv  24:             tokenizer.ggml.suffix_token_id u32              = 69\n","llama_model_loader: - kv  25:             tokenizer.ggml.middle_token_id u32              = 68\n","llama_model_loader: - kv  26:                tokenizer.ggml.eot_token_id u32              = 107\n","llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   57 tensors\n","llama_model_loader: - type  f16:  197 tensors\n","[   1/ 254]                    token_embd.weight - [ 3072, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1500.00 MiB ->   615.23 MiB\n","[   2/ 254]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[   3/ 254]                blk.0.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[   4/ 254]                blk.0.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[   5/ 254]                  blk.0.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[   6/ 254]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[   7/ 254]                  blk.0.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[   8/ 254]             blk.0.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[   9/ 254]                  blk.0.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  10/ 254]                  blk.0.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[  11/ 254]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  12/ 254]                blk.1.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[  13/ 254]                blk.1.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  14/ 254]                  blk.1.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  15/ 254]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  16/ 254]                  blk.1.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  17/ 254]             blk.1.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  18/ 254]                  blk.1.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  19/ 254]                  blk.1.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[  20/ 254]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  21/ 254]                blk.2.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[  22/ 254]                blk.2.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  23/ 254]                  blk.2.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  24/ 254]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  25/ 254]                  blk.2.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  26/ 254]             blk.2.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  27/ 254]                  blk.2.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  28/ 254]                  blk.2.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[  29/ 254]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  30/ 254]                blk.3.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  31/ 254]                blk.3.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  32/ 254]                  blk.3.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  33/ 254]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  34/ 254]                  blk.3.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  35/ 254]             blk.3.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  36/ 254]                  blk.3.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  37/ 254]                  blk.3.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  38/ 254]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  39/ 254]                blk.4.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  40/ 254]                blk.4.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  41/ 254]                  blk.4.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  42/ 254]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  43/ 254]                  blk.4.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  44/ 254]             blk.4.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  45/ 254]                  blk.4.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  46/ 254]                  blk.4.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  47/ 254]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  48/ 254]                blk.5.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[  49/ 254]                blk.5.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  50/ 254]                  blk.5.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  51/ 254]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  52/ 254]                  blk.5.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  53/ 254]             blk.5.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  54/ 254]                  blk.5.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  55/ 254]                  blk.5.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[  56/ 254]                  blk.6.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  57/ 254]             blk.6.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  58/ 254]                  blk.6.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  59/ 254]                  blk.6.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  60/ 254]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  61/ 254]               blk.10.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  62/ 254]               blk.10.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  63/ 254]                 blk.10.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  64/ 254]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  65/ 254]                 blk.10.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  66/ 254]            blk.10.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  67/ 254]                 blk.10.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  68/ 254]                 blk.10.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  69/ 254]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  70/ 254]               blk.11.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  71/ 254]               blk.11.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  72/ 254]                 blk.11.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  73/ 254]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  74/ 254]                 blk.11.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  75/ 254]            blk.11.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  76/ 254]                 blk.11.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  77/ 254]                 blk.11.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[  78/ 254]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  79/ 254]               blk.12.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[  80/ 254]               blk.12.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  81/ 254]                 blk.12.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  82/ 254]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  83/ 254]                 blk.12.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  84/ 254]            blk.12.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  85/ 254]                 blk.12.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  86/ 254]                 blk.12.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  87/ 254]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  88/ 254]               blk.13.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  89/ 254]               blk.13.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  90/ 254]                 blk.13.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  91/ 254]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  92/ 254]                 blk.13.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  93/ 254]            blk.13.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  94/ 254]                 blk.13.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  95/ 254]                 blk.13.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[  96/ 254]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  97/ 254]               blk.14.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  98/ 254]               blk.14.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[  99/ 254]                 blk.14.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 100/ 254]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 101/ 254]                 blk.14.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 102/ 254]            blk.14.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 103/ 254]                 blk.14.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 104/ 254]                 blk.14.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 105/ 254]                 blk.15.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 106/ 254]            blk.15.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 107/ 254]                 blk.15.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 108/ 254]                 blk.15.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 109/ 254]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 110/ 254]                blk.6.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 111/ 254]                blk.6.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 112/ 254]                  blk.6.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 113/ 254]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 114/ 254]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 115/ 254]                blk.7.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 116/ 254]                blk.7.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 117/ 254]                  blk.7.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 118/ 254]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 119/ 254]                  blk.7.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 120/ 254]             blk.7.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 121/ 254]                  blk.7.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 122/ 254]                  blk.7.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 123/ 254]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 124/ 254]                blk.8.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 125/ 254]                blk.8.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 126/ 254]                  blk.8.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 127/ 254]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 128/ 254]                  blk.8.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 129/ 254]             blk.8.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 130/ 254]                  blk.8.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 131/ 254]                  blk.8.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 132/ 254]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 133/ 254]                blk.9.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 134/ 254]                blk.9.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 135/ 254]                  blk.9.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 136/ 254]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 137/ 254]                  blk.9.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 138/ 254]             blk.9.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 139/ 254]                  blk.9.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 140/ 254]                  blk.9.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 141/ 254]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 142/ 254]               blk.15.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 143/ 254]               blk.15.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 144/ 254]                 blk.15.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 145/ 254]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 146/ 254]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 147/ 254]               blk.16.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 148/ 254]               blk.16.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 149/ 254]                 blk.16.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 150/ 254]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 151/ 254]                 blk.16.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 152/ 254]            blk.16.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 153/ 254]                 blk.16.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 154/ 254]                 blk.16.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 155/ 254]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 156/ 254]               blk.17.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 157/ 254]               blk.17.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 158/ 254]                 blk.17.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 159/ 254]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 160/ 254]                 blk.17.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 161/ 254]            blk.17.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 162/ 254]                 blk.17.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 163/ 254]                 blk.17.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 164/ 254]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 165/ 254]               blk.18.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 166/ 254]               blk.18.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 167/ 254]                 blk.18.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 168/ 254]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 169/ 254]                 blk.18.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 170/ 254]            blk.18.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 171/ 254]                 blk.18.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 172/ 254]                 blk.18.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 173/ 254]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 174/ 254]               blk.19.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 175/ 254]               blk.19.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 176/ 254]                 blk.19.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 177/ 254]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 178/ 254]                 blk.19.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 179/ 254]            blk.19.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 180/ 254]                 blk.19.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 181/ 254]                 blk.19.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 182/ 254]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 183/ 254]               blk.20.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 184/ 254]               blk.20.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 185/ 254]                 blk.20.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 186/ 254]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 187/ 254]                 blk.20.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 188/ 254]            blk.20.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 189/ 254]                 blk.20.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 190/ 254]                 blk.20.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 191/ 254]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 192/ 254]               blk.21.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 193/ 254]               blk.21.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 194/ 254]                 blk.21.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 195/ 254]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 196/ 254]                 blk.21.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 197/ 254]            blk.21.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 198/ 254]                 blk.21.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 199/ 254]                 blk.21.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 200/ 254]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 201/ 254]               blk.22.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 202/ 254]               blk.22.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 203/ 254]                 blk.22.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 204/ 254]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 205/ 254]                 blk.22.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 206/ 254]            blk.22.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 207/ 254]                 blk.22.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 208/ 254]                 blk.22.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 209/ 254]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 210/ 254]               blk.23.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 211/ 254]               blk.23.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 212/ 254]                 blk.23.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 213/ 254]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 214/ 254]                 blk.23.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 215/ 254]            blk.23.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 216/ 254]                 blk.23.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 217/ 254]                 blk.23.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 218/ 254]                 blk.24.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 219/ 254]            blk.24.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 220/ 254]                 blk.24.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 221/ 254]                 blk.24.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 222/ 254]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 223/ 254]               blk.24.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 224/ 254]               blk.24.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 225/ 254]                 blk.24.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 226/ 254]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 227/ 254]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 228/ 254]               blk.25.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 229/ 254]               blk.25.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 230/ 254]                 blk.25.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 231/ 254]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 232/ 254]                 blk.25.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 233/ 254]            blk.25.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 234/ 254]                 blk.25.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 235/ 254]                 blk.25.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 236/ 254]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 237/ 254]               blk.26.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 238/ 254]               blk.26.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 239/ 254]                 blk.26.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 240/ 254]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 241/ 254]                 blk.26.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 242/ 254]            blk.26.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 243/ 254]                 blk.26.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 244/ 254]                 blk.26.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 245/ 254]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 246/ 254]               blk.27.ffn_down.weight - [24576,  3072,     1,     1], type =    f16, converting to q6_K .. size =   144.00 MiB ->    59.06 MiB\n","[ 247/ 254]               blk.27.ffn_gate.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 248/ 254]                 blk.27.ffn_up.weight - [ 3072, 24576,     1,     1], type =    f16, converting to q4_K .. size =   144.00 MiB ->    40.50 MiB\n","[ 249/ 254]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 250/ 254]                 blk.27.attn_k.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 251/ 254]            blk.27.attn_output.weight - [ 4096,  3072,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 252/ 254]                 blk.27.attn_q.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q4_K .. size =    24.00 MiB ->     6.75 MiB\n","[ 253/ 254]                 blk.27.attn_v.weight - [ 3072,  4096,     1,     1], type =    f16, converting to q6_K .. size =    24.00 MiB ->     9.84 MiB\n","[ 254/ 254]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","llama_model_quantize_internal: model size  = 16284.67 MB\n","llama_model_quantize_internal: quant size  =  5077.09 MB\n","\n","main: quantize time = 148261.37 ms\n","main:    total time = 148261.37 ms\n","Unsloth: Conversion completed! Output location: ./model-unsloth.Q4_K_M.gguf\n"]}],"source":["model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30319,"status":"ok","timestamp":1718012847982,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"JuWQktPRT3hS","outputId":"950f2345-1340-48b1-a874-3d56995d53d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":21319,"status":"ok","timestamp":1718013019621,"user":{"displayName":"È©¨Â∫∑Âãá","userId":"12146428605896669618"},"user_tz":-480},"id":"PL2PY0uUT59w","outputId":"56fc7486-c275-4507-cdbb-bdcefcc0d65d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Llama3/model-unsloth.Q4_K_M.gguf'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import shutil\n","source_file = '/content/model-unsloth.Q4_K_M.gguf'\n","destination_dir = '/content/drive/MyDrive/Llama3'\n","destination_file = f'{destination_dir}/model-unsloth.Q4_K_M.gguf'\n","shutil.copy(source_file, destination_file)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMAjLwz7OTcK6cx2Z5qymaY","gpuType":"L4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"070648f8d48d40ab9bcd1f6bceca0c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09bab0c9b838403fa382a1e15125437d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe2f9db53cf4776b4a91c1c6e811845","max":1720313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95bdd8d09f154c59abef56f5f5c3368a","value":1720313}},"09bc7494dc9f4c8f981303ed900557c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e99feb2faa274d2786e789ed35cf5969","placeholder":"‚Äã","style":"IPY_MODEL_51fe1761ac204821be9f49bb0e206722","value":"‚Äá636/636‚Äá[00:00&lt;00:00,‚Äá56.8kB/s]"}},"0c39b4a0075144ed9888de66ce73d120":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f59246f099144d5b5a801541e5cceb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fd30080ad3242caa94ab7c215473f4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_400dea62d49641ae8d27c3da2a649f94","IPY_MODEL_4caa1b72cf5c4648ab768aa27bfcec39","IPY_MODEL_37e8249ff869499a8c742627fd8002e5"],"layout":"IPY_MODEL_8d00abe3071642188ebb666506c7ff5b"}},"10129f9f8b754395aea0017abc983660":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11b73034e19040f3b784c446c0734bd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16d54e6275364fc0ae11f60bf3910829":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18e836f6c3eb477f968aa2610dd659d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18e948755d1c429c8ed090847d8dfb39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19f7340a18cb449dba3ffd042818332a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b02b1fd93ed4dd2b2daadea57d68375":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3f0490659f14bc5b665c99dc1eec054","placeholder":"‚Äã","style":"IPY_MODEL_817985f8873d4df794671abdcca5d639","value":"‚Äá17.5M/17.5M‚Äá[00:00&lt;00:00,‚Äá218MB/s]"}},"1c25a5f4d47e47048e36ca4beff7ae62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c39b4a0075144ed9888de66ce73d120","placeholder":"‚Äã","style":"IPY_MODEL_11b73034e19040f3b784c446c0734bd4","value":"‚Äá40.0k/40.0k‚Äá[00:00&lt;00:00,‚Äá2.96MB/s]"}},"1d2a1e09fbd442f2932f7c4e65d0b66d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d2bb242f6564ed698acb585ab184a51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16d54e6275364fc0ae11f60bf3910829","placeholder":"‚Äã","style":"IPY_MODEL_b3b54eec74084e03b203ca0fdd47f50c","value":"‚Äá17/17‚Äá[00:05&lt;00:00,‚Äá‚Äá1.95files/s]"}},"1e82eee799674205ba7b232c20fa2d48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f0b3f6c74f743669c5765745ca47103":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f94f0985be64e04858d609e2a6f6ebe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d5b2646435f443b997ace484f3f19a5","placeholder":"‚Äã","style":"IPY_MODEL_2aa02489e64249a7b3350b9e103bdc6b","value":"‚Äá1.11k/1.11k‚Äá[00:00&lt;00:00,‚Äá89.0kB/s]"}},"218eaa83ae3b4a8c96df3b6d58d75b49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"223a6b33e00e479390a52d1619f3ea10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"286b139391bb42dba2f76de995a874fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f769c713a27a4b8cb7bfe396ebe1a023","placeholder":"‚Äã","style":"IPY_MODEL_d293bb1e11684df881774b33bca76be0","value":"special_tokens_map.json:‚Äá100%"}},"28f03c0eda6b4efda75b035280ac24d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a1eab57817442eb8697384c447a3b0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aa02489e64249a7b3350b9e103bdc6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d5b2646435f443b997ace484f3f19a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"302ff71e24254e388f1cdaba8d0bb20b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"322ec14b0e734cf28fb6750fadfb8d69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37e8249ff869499a8c742627fd8002e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebfa7d36c60b4fbfa0222f3c8c3add75","placeholder":"‚Äã","style":"IPY_MODEL_218eaa83ae3b4a8c96df3b6d58d75b49","value":"‚Äá5.57G/5.57G‚Äá[00:18&lt;00:00,‚Äá338MB/s]"}},"38f7412531f1447d8b343c1c1edc80bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_650ea41435844cfcb2b4d64898b96e2b","placeholder":"‚Äã","style":"IPY_MODEL_efda3bc6544d45f794392a35b0710448","value":"Downloading‚Äádata:‚Äá100%"}},"392db96ab8a74fbf8c47c0e873cbfae6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cfc27144cfe4aaa877f26d49709c45d","IPY_MODEL_c1f8ebcf7ed244c0b562068d2418e975","IPY_MODEL_3d319100c7d740369971bca41ceaecf4"],"layout":"IPY_MODEL_476385dfd4274a8f893be9ef3f604836"}},"3b095a293fb546319557b3e712722335":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b1ea9d4527d4527b806e078c74b5af7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d319100c7d740369971bca41ceaecf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae863ed04ccc47279a94696ebaac4985","placeholder":"‚Äã","style":"IPY_MODEL_f312007d7c234feaa1068aac1abbab94","value":"‚Äá4.24M/4.24M‚Äá[00:00&lt;00:00,‚Äá18.5MB/s]"}},"3f7e583841c64e0a9ead18873e2af587":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fe90894dde6465d95497d05729feb11","IPY_MODEL_a3cd2bb2c6c54ace9518fd332c0b3c05","IPY_MODEL_1f94f0985be64e04858d609e2a6f6ebe"],"layout":"IPY_MODEL_ad5e9d0de533489d8c4219e53d935170"}},"400dea62d49641ae8d27c3da2a649f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d07d380653fc42f78b3874760c3718ab","placeholder":"‚Äã","style":"IPY_MODEL_19f7340a18cb449dba3ffd042818332a","value":"model.safetensors:‚Äá100%"}},"42b4c98ac5744d868b44004f06d120d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456a2dc089fd437cb94408973e2cd105":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4a6d4efec544181ba8d149a9aadb969","IPY_MODEL_e5ba232023fb413f9f6ba19c711d169e","IPY_MODEL_9d582ac8dc3548f381d8b6154db1b43f"],"layout":"IPY_MODEL_223a6b33e00e479390a52d1619f3ea10"}},"476385dfd4274a8f893be9ef3f604836":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49e630a28f2d4131a49c580e40f17ea0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c47aab1823d4f6aa250f2ff548c7f7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4caa1b72cf5c4648ab768aa27bfcec39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c06637de3bb45b9ac7c9c5a2d461a22","max":5572148372,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f0b3f6c74f743669c5765745ca47103","value":5572148372}},"4efd5890664748e8a631a38a96cdcbef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7afac6fc0b4740b65898ebc8706480":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf4d92e7cbc6493c9a7fa62b72651c46","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3c91e82dfef4fca984afa36ba016985","value":636}},"51fe1761ac204821be9f49bb0e206722":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5273b4cf4df5449d952c8e900cc8794c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54efd9ad54e74507bbaceb98b03a96b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5775e9abe7894acabd1c404cfeaa9a83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5804ab1d00c84aa8b22e4718cecd49f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5273b4cf4df5449d952c8e900cc8794c","max":137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b095a293fb546319557b3e712722335","value":137}},"5b9d1352d3e5481eb706145a8d2ee2a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bdd09119f5444808df648202d962838":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b51e582d030404db44e323598507712","max":17518497,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7746eb8e2bed47119bfeaaf335bb2760","value":17518497}},"60807a58b44e4a7dba7f3a2961ff2895":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61f3e93d4983449c97d50a0c0094d04b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"650ea41435844cfcb2b4d64898b96e2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65430c69598d47cb8502eac2c564e4d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c06637de3bb45b9ac7c9c5a2d461a22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"716d66e6ed434183aa683fe9783cbd05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76aafe9a90b5419a9426cf5c8ddf7c65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7746eb8e2bed47119bfeaaf335bb2760":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7fba1d2debb04e6da87906fb2a15b162":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0fe8595ec7e423fb64a149fb9794258","placeholder":"‚Äã","style":"IPY_MODEL_18e948755d1c429c8ed090847d8dfb39","value":"Resolving‚Äádata‚Äáfiles:‚Äá100%"}},"817985f8873d4df794671abdcca5d639":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cfc27144cfe4aaa877f26d49709c45d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b9d1352d3e5481eb706145a8d2ee2a2","placeholder":"‚Äã","style":"IPY_MODEL_d49e122514da458abce86544fda5332b","value":"tokenizer.model:‚Äá100%"}},"8d00abe3071642188ebb666506c7ff5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ddcf52acd6c4561a5061f8bf5986147":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_286b139391bb42dba2f76de995a874fe","IPY_MODEL_4f7afac6fc0b4740b65898ebc8706480","IPY_MODEL_09bc7494dc9f4c8f981303ed900557c6"],"layout":"IPY_MODEL_18e836f6c3eb477f968aa2610dd659d6"}},"8f1ccafe693d4b1e99ab75dd9cd18523":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee7094c276b344538c80fb249589d38c","placeholder":"‚Äã","style":"IPY_MODEL_49e630a28f2d4131a49c580e40f17ea0","value":"tokenizer_config.json:‚Äá100%"}},"8f3d15b379e3431ba25f00c81c6f5d88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9004f0c84f5d43b5bc40d5e567949d92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60807a58b44e4a7dba7f3a2961ff2895","placeholder":"‚Äã","style":"IPY_MODEL_4c47aab1823d4f6aa250f2ff548c7f7b","value":"Map‚Äá(num_proc=2):‚Äá100%"}},"929521bfb14c4439b14873fb897d431b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95905e7cb1be47e58ef2e657eff8ef4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95bdd8d09f154c59abef56f5f5c3368a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"965b06fc492240719d08ce5adaf5fc95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96c96f1a441243e097a0d3005066e3ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"982f3b89e6ef49498b34a689d3981458":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd9e2e85e9d54c359129faf5e76eb37e","placeholder":"‚Äã","style":"IPY_MODEL_96c96f1a441243e097a0d3005066e3ee","value":"Map:‚Äá100%"}},"986a7b84deed46dc9d43c0a8763c7e28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5ff59d50db24302bfbf9db2fb0ec0ec","IPY_MODEL_5bdd09119f5444808df648202d962838","IPY_MODEL_1b02b1fd93ed4dd2b2daadea57d68375"],"layout":"IPY_MODEL_302ff71e24254e388f1cdaba8d0bb20b"}},"9aa1208a920c47fb82cc7b90294b08d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aed71e59cfd46e1a7cd100b177c1413":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b51e582d030404db44e323598507712":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b8ca62dc9964fd5b81a2f89a3fc0b3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d582ac8dc3548f381d8b6154db1b43f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceb60498584140ddbf624a57974f5b52","placeholder":"‚Äã","style":"IPY_MODEL_c8acb54a0ea34c328b94f1292a582d03","value":"‚Äá1720313/1720313‚Äá[00:10&lt;00:00,‚Äá155857.44‚Äáexamples/s]"}},"9d8258e8950846d3b1cc95943084626e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38f7412531f1447d8b343c1c1edc80bc","IPY_MODEL_b785ea153c334d6fa381a6572943be6b","IPY_MODEL_1d2bb242f6564ed698acb585ab184a51"],"layout":"IPY_MODEL_cb7ea8881a634fcb9df3823795b4d6bd"}},"9ef51230979a4e09adf703924721f976":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f1ccafe693d4b1e99ab75dd9cd18523","IPY_MODEL_c43deac2bebc42e1bede0c8e38cb94ad","IPY_MODEL_1c25a5f4d47e47048e36ca4beff7ae62"],"layout":"IPY_MODEL_edb817f7eedc4316b888358f33f5db36"}},"9fe90894dde6465d95497d05729feb11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da35870559734bfda0e8e7a8a822d340","placeholder":"‚Äã","style":"IPY_MODEL_54efd9ad54e74507bbaceb98b03a96b2","value":"config.json:‚Äá100%"}},"a06c7694e10945fbae365991ce34d4bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_982f3b89e6ef49498b34a689d3981458","IPY_MODEL_09bab0c9b838403fa382a1e15125437d","IPY_MODEL_ac54531bb5844cfd9fa93ab4c6695a2a"],"layout":"IPY_MODEL_61f3e93d4983449c97d50a0c0094d04b"}},"a3cd2bb2c6c54ace9518fd332c0b3c05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76aafe9a90b5419a9426cf5c8ddf7c65","max":1109,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28f03c0eda6b4efda75b035280ac24d0","value":1109}},"ac54531bb5844cfd9fa93ab4c6695a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_322ec14b0e734cf28fb6750fadfb8d69","placeholder":"‚Äã","style":"IPY_MODEL_929521bfb14c4439b14873fb897d431b","value":"‚Äá1720313/1720313‚Äá[00:10&lt;00:00,‚Äá143346.23‚Äáexamples/s]"}},"ad5e9d0de533489d8c4219e53d935170":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae863ed04ccc47279a94696ebaac4985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2b28af5c4748f09e36cb0537146bb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3b54eec74084e03b203ca0fdd47f50c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5ff59d50db24302bfbf9db2fb0ec0ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc1fe363fdbe428cb3117309f3cc4e13","placeholder":"‚Äã","style":"IPY_MODEL_2a1eab57817442eb8697384c447a3b0c","value":"tokenizer.json:‚Äá100%"}},"b785ea153c334d6fa381a6572943be6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5775e9abe7894acabd1c404cfeaa9a83","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e82eee799674205ba7b232c20fa2d48","value":17}},"bc1fe363fdbe428cb3117309f3cc4e13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc5405d47b340709ff37a1c4dae3fcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf6078095fc34928a48e2a6a8bbe6d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40337f6e6234c92b520e4191bb20153","placeholder":"‚Äã","style":"IPY_MODEL_10129f9f8b754395aea0017abc983660","value":"‚Äá17/17‚Äá[00:00&lt;00:00,‚Äá‚Äá5.26it/s]"}},"c1f8ebcf7ed244c0b562068d2418e975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42b4c98ac5744d868b44004f06d120d8","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_716d66e6ed434183aa683fe9783cbd05","value":4241003}},"c29e6d15833f4a91ba46641e1231bfd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aa1208a920c47fb82cc7b90294b08d5","placeholder":"‚Äã","style":"IPY_MODEL_965b06fc492240719d08ce5adaf5fc95","value":"‚Äá137/137‚Äá[00:00&lt;00:00,‚Äá12.3kB/s]"}},"c3c91e82dfef4fca984afa36ba016985":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c40337f6e6234c92b520e4191bb20153":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c43deac2bebc42e1bede0c8e38cb94ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1e1417050ab4d70a15234c10f518153","max":39991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcc5405d47b340709ff37a1c4dae3fcf","value":39991}},"c4a6d4efec544181ba8d149a9aadb969":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f3d15b379e3431ba25f00c81c6f5d88","placeholder":"‚Äã","style":"IPY_MODEL_0f59246f099144d5b5a801541e5cceb4","value":"Generating‚Äátrain‚Äásplit:‚Äá100%"}},"c80b88a3c4c244f5a9b7b2b47d106c24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8135a01d5b9447dbff0971545b94176":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef1374654a1d4cee9effdb9d9adef11e","placeholder":"‚Äã","style":"IPY_MODEL_1d2a1e09fbd442f2932f7c4e65d0b66d","value":"generation_config.json:‚Äá100%"}},"c8acb54a0ea34c328b94f1292a582d03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb7ea8881a634fcb9df3823795b4d6bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe2f9db53cf4776b4a91c1c6e811845":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc4d682d38924b109d1191f2e9db34c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7fba1d2debb04e6da87906fb2a15b162","IPY_MODEL_eaf0574f20e44503b876687801109319","IPY_MODEL_bf6078095fc34928a48e2a6a8bbe6d08"],"layout":"IPY_MODEL_95905e7cb1be47e58ef2e657eff8ef4b"}},"ceb60498584140ddbf624a57974f5b52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf4d92e7cbc6493c9a7fa62b72651c46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d07d380653fc42f78b3874760c3718ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14001408bf64ba4ac2301f595e9a976":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9004f0c84f5d43b5bc40d5e567949d92","IPY_MODEL_f15a56ad68eb43d3814825227c0d7c0d","IPY_MODEL_d75205aa75e3435cb5b7bf88976aea7e"],"layout":"IPY_MODEL_e4cc39642b514579bbc50a9ce2014133"}},"d293bb1e11684df881774b33bca76be0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d49e122514da458abce86544fda5332b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d75205aa75e3435cb5b7bf88976aea7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b1ea9d4527d4527b806e078c74b5af7","placeholder":"‚Äã","style":"IPY_MODEL_65430c69598d47cb8502eac2c564e4d0","value":"‚Äá1720313/1720313‚Äá[04:34&lt;00:00,‚Äá3495.31‚Äáexamples/s]"}},"d7f1d7cc51de41a7b17a974d00fcd8da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da35870559734bfda0e8e7a8a822d340":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9e2e85e9d54c359129faf5e76eb37e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fe8595ec7e423fb64a149fb9794258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e1417050ab4d70a15234c10f518153":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4cc39642b514579bbc50a9ce2014133":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5ba232023fb413f9f6ba19c711d169e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7f1d7cc51de41a7b17a974d00fcd8da","max":1720313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b8ca62dc9964fd5b81a2f89a3fc0b3f","value":1720313}},"e99feb2faa274d2786e789ed35cf5969":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf0574f20e44503b876687801109319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_070648f8d48d40ab9bcd1f6bceca0c8d","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c80b88a3c4c244f5a9b7b2b47d106c24","value":17}},"ebfa7d36c60b4fbfa0222f3c8c3add75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edb817f7eedc4316b888358f33f5db36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee7094c276b344538c80fb249589d38c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1374654a1d4cee9effdb9d9adef11e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efda3bc6544d45f794392a35b0710448":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f15a56ad68eb43d3814825227c0d7c0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4efd5890664748e8a631a38a96cdcbef","max":1720313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af2b28af5c4748f09e36cb0537146bb5","value":1720313}},"f312007d7c234feaa1068aac1abbab94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3f0490659f14bc5b665c99dc1eec054":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f769c713a27a4b8cb7bfe396ebe1a023":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9c4d72cfa724983b19b073225db3cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8135a01d5b9447dbff0971545b94176","IPY_MODEL_5804ab1d00c84aa8b22e4718cecd49f5","IPY_MODEL_c29e6d15833f4a91ba46641e1231bfd0"],"layout":"IPY_MODEL_9aed71e59cfd46e1a7cd100b177c1413"}}}}},"nbformat":4,"nbformat_minor":0}
